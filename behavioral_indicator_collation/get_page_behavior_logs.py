#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Get Page Behavior Logs
è·å–å¹¶åˆ†æpageBehaviorLogsæ•°æ®ï¼Œç”Ÿæˆç±»ä¼¼è¯­éŸ³æ•°æ®çš„CSVæ–‡ä»¶
"""

import json
import csv
import pandas as pd
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Tuple, Any
import os
import firebase_admin
from firebase_admin import credentials, firestore
from google.cloud.firestore_v1 import FieldFilter

def convert_east8_to_utc(east8_time_str):
    """å°†ä¸œå…«åŒºæ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºUTCæ—¶é—´"""
    # è§£æä¸œå…«åŒºæ—¶é—´
    east8_time = datetime.strptime(east8_time_str, "%Y-%m-%d %H:%M:%S")
    # è½¬æ¢ä¸ºUTCæ—¶é—´ï¼ˆå‡å»8å°æ—¶ï¼‰
    utc_time = east8_time - timedelta(hours=8)
    return utc_time.replace(tzinfo=timezone.utc)

class PageBehaviorAnalyzer:
    def __init__(self, mapping_file: str, output_file: str):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            mapping_file: complete_groups_mapping.jsonæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„
        """
        self.mapping_file = mapping_file
        self.output_file = output_file
        self.groups_mapping = {}
        self.user_to_group = {}
        self.time_columns = []
        
    def load_groups_mapping(self):
        """åŠ è½½ç»„æ˜ å°„ä¿¡æ¯"""
        try:
            with open(self.mapping_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.groups_mapping = data.get('groups_mapping', [])
                
            print(f"\nğŸ“‹ å¼€å§‹åŠ è½½ç»„æ˜ å°„ä¿¡æ¯...")
            print(f"   é…ç½®æ–‡ä»¶: {self.mapping_file}")
            print(f"   æ€»ç»„æ•°: {len(self.groups_mapping)}")
            
            # å»ºç«‹ç”¨æˆ·IDåˆ°ç»„ä¿¡æ¯çš„æ˜ å°„
            for i, group in enumerate(self.groups_mapping):
                group_key = group['group_key']
                base_time_str = group['base_time_str']
                
                print(f"\nğŸ” æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(self.groups_mapping)} ä¸ªç»„: {group_key}")
                print(f"   åŸå§‹æ—¶é—´: {base_time_str}")
                
                # è§£æç»„å¼€å§‹æ—¶é—´ï¼ˆä¸œå…«åŒºï¼‰å¹¶è½¬æ¢ä¸ºUTC
                try:
                    base_time_utc = convert_east8_to_utc(base_time_str)
                    group['base_time'] = base_time_utc
                    print(f"   UTCæ—¶é—´: {base_time_utc}")
                except ValueError as e:
                    print(f"   âŒ è§£æç»„ {group_key} çš„å¼€å§‹æ—¶é—´å¤±è´¥: {e}")
                    continue
                
                # æ˜¾ç¤ºç»„æˆå‘˜ä¿¡æ¯
                group_members = group.get('group_members', [])
                print(f"   æˆå‘˜æ•°é‡: {len(group_members)}")
                
                # å»ºç«‹ç”¨æˆ·æ˜ å°„
                for j, member in enumerate(group_members):
                    user_id = member['user_id']
                    speaker = member['speaker']
                    self.user_to_group[user_id] = {
                        'group_key': group_key,
                        'speaker': speaker,
                        'base_time': base_time_utc
                    }
                    print(f"     - æˆå‘˜ {j+1}/{len(group_members)}: ç”¨æˆ·ID {user_id[:8]}... (å‘è¨€è€…: {speaker})")
                    
            print(f"\nâœ… æˆåŠŸåŠ è½½ {len(self.groups_mapping)} ä¸ªç»„ï¼Œ{len(self.user_to_group)} ä¸ªç”¨æˆ·")
            print(f"   ç”¨æˆ·æ˜ å°„è¡¨å¤§å°: {len(self.user_to_group)}")
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç»„æ˜ å°„æ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def generate_time_columns(self):
        """ç”Ÿæˆ30åˆ†é’Ÿçš„æ—¶é—´åˆ—ï¼ˆæ¯10ç§’ä¸€ä¸ªé—´éš”ï¼‰"""
        self.time_columns = []
        for i in range(180):  # 30åˆ†é’Ÿ = 180ä¸ª10ç§’é—´éš”
            start_min = i // 6
            start_sec = (i % 6) * 10
            end_min = (i + 1) // 6
            end_sec = ((i + 1) % 6) * 10
            
            if end_sec == 0:
                end_sec = 60
                end_min -= 1
                
            time_col = f"{start_min:02d}:{start_sec:02d}-{end_min:02d}:{end_sec:02d}"
            self.time_columns.append(time_col)
        
        print(f"ç”Ÿæˆ {len(self.time_columns)} ä¸ªæ—¶é—´åˆ—")
    
    def parse_utc_time(self, utc_str: str) -> datetime:
        """è§£æUTCæ—¶é—´å­—ç¬¦ä¸²"""
        try:
            # ç§»é™¤Zåç¼€å¹¶æ·»åŠ +00:00æ—¶åŒºæ ‡è¯†
            utc_str_clean = utc_str.replace('Z', '+00:00')
            utc_time = datetime.fromisoformat(utc_str_clean)
            return utc_time
        except Exception as e:
            print(f"è§£ææ—¶é—´å¤±è´¥ {utc_str}: {e}")
            return None
    
    def calculate_time_interval(self, behavior_time: datetime, group_base_time: datetime) -> int:
        """
        è®¡ç®—è¡Œä¸ºæ—¶é—´ç›¸å¯¹äºç»„å¼€å§‹æ—¶é—´çš„10ç§’é—´éš”ç´¢å¼•
        
        Args:
            behavior_time: è¡Œä¸ºæ—¶é—´ï¼ˆUTCï¼‰
            group_base_time: ç»„å¼€å§‹æ—¶é—´ï¼ˆUTCï¼‰
            
        Returns:
            10ç§’é—´éš”çš„ç´¢å¼•ï¼ˆ0-179ï¼‰ï¼Œå¦‚æœè¶…å‡º30åˆ†é’ŸèŒƒå›´åˆ™è¿”å›-1
        """
        time_diff = behavior_time - group_base_time
        seconds_diff = time_diff.total_seconds()
        
        # æ£€æŸ¥æ˜¯å¦åœ¨30åˆ†é’ŸèŒƒå›´å†…
        if 0 <= seconds_diff <= 1800:  # 30åˆ†é’Ÿ = 1800ç§’
            interval_index = int(seconds_diff / 10)
            return min(interval_index, 179)  # ç¡®ä¿ä¸è¶…è¿‡179
        else:
            return -1  # è¶…å‡ºèŒƒå›´
    
    def process_time_alignment(self, behavior_data: List[Dict]) -> List[Dict]:
        """
        å¤„ç†æ—¶é—´å¯¹é½é€»è¾‘
        
        Args:
            behavior_data: åŸå§‹pageBehaviorLogsæ•°æ®
            
        Returns:
            æ·»åŠ äº†æ—¶é—´å¯¹é½ä¿¡æ¯çš„æ•°æ®
        """
        print(f"\nğŸ”„ å¼€å§‹æ—¶é—´å¯¹é½å¤„ç†...")
        print(f"   åŸå§‹æ•°æ®æ¡æ•°: {len(behavior_data)}")
        
        aligned_data = []
        skipped_user_not_found = 0
        skipped_no_window_start = 0
        skipped_time_parse_failed = 0
        skipped_out_of_range = 0
        
        # ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·çš„è®°å½•æ•°
        user_record_counts = {}
        group_record_counts = {}
        
        for i, record in enumerate(behavior_data):
            if i < 5:  # åªæ‰“å°å‰5æ¡è®°å½•çš„è¯¦ç»†ä¿¡æ¯
                print(f"\n   è®°å½• {i+1}:")
                print(f"     userId: {record.get('userId', 'N/A')}")
                print(f"     windowStart: {record.get('windowStart', 'N/A')}")
                print(f"     behaviorData keys: {list(record.get('behaviorData', {}).keys())}")
            
            user_id = record.get('userId')
            
            # ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·çš„è®°å½•æ•°
            if user_id:
                user_record_counts[user_id] = user_record_counts.get(user_id, 0) + 1
                
                # å¦‚æœç”¨æˆ·ä¸åœ¨æ˜ å°„è¡¨ä¸­ï¼Œç»Ÿè®¡åˆ°ç»„"æœªæ˜ å°„"
                if user_id not in self.user_to_group:
                    group_key = "æœªæ˜ å°„"
                else:
                    group_key = self.user_to_group[user_id]['group_key']
                    # ç»Ÿè®¡æ¯ä¸ªç»„çš„è®°å½•æ•°
                    group_record_counts[group_key] = group_record_counts.get(group_key, 0) + 1
            
            if user_id not in self.user_to_group:
                skipped_user_not_found += 1
                if i < 5:
                    print(f"     âŒ ç”¨æˆ·IDä¸åœ¨æ˜ å°„è¡¨ä¸­")
                continue
                
            window_start = record.get('windowStart')
            if not window_start:
                skipped_no_window_start += 1
                if i < 5:
                    print(f"     âŒ ç¼ºå°‘windowStartå­—æ®µ")
                continue
                
            # è§£ææ—¶é—´
            behavior_time = self.parse_utc_time(window_start)
            if not behavior_time:
                skipped_time_parse_failed += 1
                if i < 5:
                    print(f"     âŒ æ—¶é—´è§£æå¤±è´¥")
                continue
                
            # è·å–ç»„ä¿¡æ¯
            group_info = self.user_to_group[user_id]
            group_base_time = group_info['base_time']
            
            if i < 5:
                print(f"     âœ… ç”¨æˆ·åŒ¹é…æˆåŠŸ: {group_info['group_key']} - {group_info['speaker']}")
                print(f"     è¡Œä¸ºæ—¶é—´: {behavior_time}")
                print(f"     ç»„åŸºå‡†æ—¶é—´: {group_base_time}")
            
            # è®¡ç®—æ—¶é—´é—´éš”ç´¢å¼•
            interval_index = self.calculate_time_interval(behavior_time, group_base_time)
            if interval_index == -1:
                skipped_out_of_range += 1
                if i < 5:
                    print(f"     âŒ æ—¶é—´è¶…å‡º30åˆ†é’ŸèŒƒå›´")
                continue
                
            if i < 5:
                print(f"     âœ… æ—¶é—´å¯¹é½æˆåŠŸ: é—´éš”ç´¢å¼• {interval_index}")
            
            # æ·»åŠ æ—¶é—´å¯¹é½ä¿¡æ¯
            aligned_record = record.copy()
            aligned_record['interval_index'] = interval_index
            aligned_record['group_info'] = group_info
            aligned_data.append(aligned_record)
        
        # æ‰“å°ç”¨æˆ·è®°å½•æ•°ç»Ÿè®¡
        print(f"\nğŸ“Š ç”¨æˆ·è®°å½•æ•°ç»Ÿè®¡:")
        print(f"   æ€»ç”¨æˆ·æ•°: {len(user_record_counts)}")
        print(f"   å‰10ä¸ªç”¨æˆ·çš„è®°å½•æ•°:")
        sorted_users = sorted(user_record_counts.items(), key=lambda x: x[1], reverse=True)
        for i, (user_id, count) in enumerate(sorted_users[:10]):
            if user_id in self.user_to_group:
                group_info = self.user_to_group[user_id]
                print(f"     {i+1}. ç”¨æˆ· {user_id[:8]}... ({group_info['group_key']}-{group_info['speaker']}): {count} æ¡è®°å½•")
            else:
                print(f"     {i+1}. ç”¨æˆ· {user_id[:8]}... (æœªæ˜ å°„): {count} æ¡è®°å½•")
        
        # æ‰“å°ç»„è®°å½•æ•°ç»Ÿè®¡
        print(f"\nğŸ“Š ç»„è®°å½•æ•°ç»Ÿè®¡:")
        print(f"   æ€»ç»„æ•°: {len(group_record_counts)}")
        print(f"   å„ç»„è®°å½•æ•°:")
        sorted_groups = sorted(group_record_counts.items(), key=lambda x: x[1], reverse=True)
        for group_key, count in sorted_groups:
            print(f"     {group_key}: {count} æ¡è®°å½•")
        
        print(f"\nğŸ“Š æ—¶é—´å¯¹é½ç»Ÿè®¡:")
        print(f"   åŸå§‹æ•°æ®: {len(behavior_data)} æ¡")
        print(f"   ç”¨æˆ·IDä¸åŒ¹é…: {skipped_user_not_found} æ¡")
        print(f"   ç¼ºå°‘windowStart: {skipped_no_window_start} æ¡")
        print(f"   æ—¶é—´è§£æå¤±è´¥: {skipped_time_parse_failed} æ¡")
        print(f"   æ—¶é—´è¶…å‡ºèŒƒå›´: {skipped_out_of_range} æ¡")
        print(f"   æˆåŠŸå¯¹é½: {len(aligned_data)} æ¡")
        
        return aligned_data
    
    def aggregate_behavior_data(self, aligned_data: List[Dict]) -> Dict[str, List[int]]:
        """
        èšåˆè¡Œä¸ºæ•°æ®åˆ°10ç§’é—´éš”
        
        Args:
            aligned_data: æ—¶é—´å¯¹é½åçš„æ•°æ®
            
        Returns:
            ç”¨æˆ·IDåˆ°æ—¶é—´é—´éš”æ•°æ®çš„æ˜ å°„
        """
        print(f"\nğŸ“ˆ å¼€å§‹æ•°æ®èšåˆ...")
        print(f"   å¯¹é½åæ•°æ®æ¡æ•°: {len(aligned_data)}")
        
        user_data = {}
        
        # åˆå§‹åŒ–æ‰€æœ‰ç”¨æˆ·çš„æ•°æ®ç»“æ„
        for user_id in self.user_to_group:
            user_data[user_id] = [0] * 180  # 180ä¸ª10ç§’é—´éš”
        
        print(f"   åˆå§‹åŒ–äº† {len(user_data)} ä¸ªç”¨æˆ·çš„æ•°æ®ç»“æ„")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_actions = 0
        users_with_actions = set()
        
        # å¡«å……æ•°æ®
        for i, record in enumerate(aligned_data):
            user_id = record.get('userId')
            interval_index = record.get('interval_index')
            
            # è®¡ç®—mouse_action_count
            behavior_logs = record.get('behaviorData', {}).get('tabBehaviorLogs', [])
            action_count = len(behavior_logs)
            
            if i < 5:  # æ‰“å°å‰5æ¡è®°å½•çš„è¯¦ç»†ä¿¡æ¯
                print(f"\n   èšåˆè®°å½• {i+1}:")
                print(f"     userId: {user_id}")
                print(f"     é—´éš”ç´¢å¼•: {interval_index}")
                print(f"     tabBehaviorLogsé•¿åº¦: {action_count}")
                print(f"     behaviorData keys: {list(record.get('behaviorData', {}).keys())}")
            
            # å¡«å……åˆ°å¯¹åº”çš„æ—¶é—´é—´éš”
            user_data[user_id][interval_index] = action_count
            
            total_actions += action_count
            if action_count > 0:
                users_with_actions.add(user_id)
        
        # ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·çš„éé›¶é—´éš”æ•°é‡
        non_zero_intervals = {}
        for user_id, time_data in user_data.items():
            non_zero_count = sum(1 for count in time_data if count > 0)
            non_zero_intervals[user_id] = non_zero_count
        
        print(f"\nğŸ“Š æ•°æ®èšåˆç»Ÿè®¡:")
        print(f"   æ€»è¡Œä¸ºæ¬¡æ•°: {total_actions}")
        print(f"   æœ‰è¡Œä¸ºçš„ç”¨æˆ·æ•°: {len(users_with_actions)}")
        print(f"   ç”¨æˆ·è¡Œä¸ºåˆ†å¸ƒ:")
        for user_id, non_zero_count in list(non_zero_intervals.items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªç”¨æˆ·
            group_info = self.user_to_group.get(user_id, {})
            group_key = group_info.get('group_key', 'N/A')
            speaker = group_info.get('speaker', 'N/A')
            print(f"     {user_id[:8]}... ({group_key}-{speaker}): {non_zero_count} ä¸ªéé›¶é—´éš”")
        
        return user_data
    
    def generate_csv(self, user_data: Dict[str, List[int]]):
        """ç”ŸæˆCSVæ–‡ä»¶"""
        try:
            with open(self.output_file, 'w', newline='', encoding='utf-8') as csvfile:
                # å†™å…¥è¡¨å¤´
                fieldnames = ['group_key', 'speaker'] + self.time_columns
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                # å†™å…¥æ•°æ®
                for user_id, time_data in user_data.items():
                    if user_id not in self.user_to_group:
                        continue
                        
                    group_info = self.user_to_group[user_id]
                    row = {
                        'group_key': group_info['group_key'],
                        'speaker': group_info['speaker']
                    }
                    
                    # æ·»åŠ æ—¶é—´åˆ—æ•°æ®
                    for i, count in enumerate(time_data):
                        row[self.time_columns[i]] = count
                    
                    writer.writerow(row)
                    
            print(f"æˆåŠŸç”ŸæˆCSVæ–‡ä»¶: {self.output_file}")
            
        except Exception as e:
            print(f"ç”ŸæˆCSVæ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def analyze_and_export(self, behavior_data: List[Dict]):
        """ä¸»åˆ†ææµç¨‹"""
        print("å¼€å§‹åˆ†æpageBehaviorLogsæ•°æ®...")
        
        # åŠ è½½ç»„æ˜ å°„
        self.load_groups_mapping()
        
        # ç”Ÿæˆæ—¶é—´åˆ—
        self.generate_time_columns()
        
        # æ—¶é—´å¯¹é½å¤„ç†
        aligned_data = self.process_time_alignment(behavior_data)
        
        # æ•°æ®èšåˆ
        user_data = self.aggregate_behavior_data(aligned_data)
        
        # ç”ŸæˆCSVæ–‡ä»¶
        self.generate_csv(user_data)
        
        print("åˆ†æå®Œæˆï¼")
        
        # è¿”å›ç»Ÿè®¡ä¿¡æ¯
        return {
            'total_groups': len(self.groups_mapping),
            'total_users': len(user_data),
            'time_intervals': len(self.time_columns),
            'output_file': self.output_file
        }

def get_page_behavior_logs():
    """ä»Firebaseè·å–pageBehaviorLogsæ•°æ®ï¼ŒæŒ‰ç»„é€ä¸ªæŸ¥è¯¢"""
    try:
        # åˆå§‹åŒ–Firebaseåº”ç”¨
        cred = credentials.Certificate("firebase-key.json")
        firebase_admin.initialize_app(cred)
        db = firestore.client()
        
        print("âœ… Firebaseè¿æ¥æˆåŠŸï¼")
        
        # å…ˆåŠ è½½ç»„æ˜ å°„ä¿¡æ¯
        mapping_file = "complete_groups_mapping.json"
        with open(mapping_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            groups_mapping = data.get('groups_mapping', [])
        
        print(f"\nğŸ“‹ åŠ è½½äº† {len(groups_mapping)} ä¸ªç»„çš„ä¿¡æ¯")
        
        all_behavior_data = []
        group_records = {}  # æ¯ä¸ªç»„çš„è®°å½•æ•°
        user_records = {}   # æ¯ä¸ªç”¨æˆ·çš„è®°å½•æ•°
        
        # æŒ‰ç»„é€ä¸ªæŸ¥è¯¢
        for i, group in enumerate(groups_mapping):
            group_key = group['group_key']
            group_members = group.get('group_members', [])
            base_time_str = group.get('base_time_str', 'N/A')
            
            # è§£æç»„å¼€å§‹æ—¶é—´ï¼ˆä¸œå…«åŒºï¼‰å¹¶è½¬æ¢ä¸ºUTC
            try:
                base_time_utc = convert_east8_to_utc(base_time_str)
                group['base_time'] = base_time_utc
                utc_time_str = base_time_utc.strftime("%Y-%m-%d %H:%M:%S UTC")
            except ValueError as e:
                print(f"   âŒ è§£æç»„ {group_key} çš„å¼€å§‹æ—¶é—´å¤±è´¥: {e}")
                utc_time_str = "æ—¶é—´è§£æå¤±è´¥"
                continue
            
            print(f"\nğŸ” æ­£åœ¨æŸ¥è¯¢ç¬¬ {i+1}/{len(groups_mapping)} ä¸ªç»„: {group_key}")
            print(f"   ç»„å¼€å§‹æ—¶é—´: {base_time_str} (ä¸œå…«åŒº) â†’ {utc_time_str}")
            print(f"   ç»„æˆå‘˜æ•°: {len(group_members)}")
            
            group_total_records = 0
            group_earliest_window_start = None  # è®°å½•è¯¥ç»„æœ€æ—©çš„windowStart
            
            # æŸ¥è¯¢è¿™ä¸ªç»„æ¯ä¸ªæˆå‘˜çš„pageBehaviorLogs
            for j, member in enumerate(group_members):
                user_id = member['user_id']
                speaker = member['speaker']
                
                print(f"     - æŸ¥è¯¢æˆå‘˜ {j+1}/{len(group_members)}: {user_id[:8]}... ({speaker})")
                
                # æŸ¥è¯¢è¿™ä¸ªç”¨æˆ·çš„pageBehaviorLogs
                try:
                    docs = db.collection("pageBehaviorLogs").where("userId", "==", user_id).stream()
                    user_data = []
                    for doc in docs:
                        behavior_data = doc.to_dict()
                        user_data.append(behavior_data)
                        
                        # æ£€æŸ¥windowStartæ—¶é—´ï¼Œæ‰¾åˆ°æœ€æ—©çš„
                        window_start = behavior_data.get('windowStart')
                        if window_start:
                            if group_earliest_window_start is None or window_start < group_earliest_window_start:
                                group_earliest_window_start = window_start
                    
                    user_records[user_id] = len(user_data)
                    group_total_records += len(user_data)
                    
                    print(f"       æ‰¾åˆ° {len(user_data)} æ¡è®°å½•")
                    
                    # æ·»åŠ åˆ°æ€»æ•°æ®ä¸­
                    all_behavior_data.extend(user_data)
                    
                except Exception as e:
                    print(f"       æŸ¥è¯¢ç”¨æˆ· {user_id[:8]}... å¤±è´¥: {e}")
                    user_records[user_id] = 0
            
            # è®°å½•è¿™ä¸ªç»„çš„æ€»è®°å½•æ•°
            group_records[group_key] = group_total_records
            
            # æ‰“å°è¯¥ç»„æœ€æ—©çš„windowStartæ—¶é—´
            if group_earliest_window_start:
                print(f"   ğŸ“… è¯¥ç»„æœ€æ—©çš„windowStart: {group_earliest_window_start}")
            else:
                print(f"   ğŸ“… è¯¥ç»„æ²¡æœ‰æ‰¾åˆ°windowStartæ•°æ®")
                
            print(f"   âœ… ç»„ {group_key} æŸ¥è¯¢å®Œæˆï¼Œæ€»è®¡ {group_total_records} æ¡è®°å½•")
        
        print(f"\nâœ… æ‰€æœ‰ç»„æŸ¥è¯¢å®Œæˆï¼")
        print(f"   æ€»è®°å½•æ•°: {len(all_behavior_data)}")
        
        # æ‰“å°ç»„è®°å½•æ•°ç»Ÿè®¡
        print(f"\nğŸ“Š å„ç»„è®°å½•æ•°ç»Ÿè®¡:")
        for group_key, count in group_records.items():
            print(f"   {group_key}: {count} æ¡è®°å½•")
        
        # æ‰“å°ç”¨æˆ·è®°å½•æ•°ç»Ÿè®¡
        print(f"\nğŸ“Š å„ç”¨æˆ·è®°å½•æ•°ç»Ÿè®¡:")
        sorted_users = sorted(user_records.items(), key=lambda x: x[1], reverse=True)
        for i, (user_id, count) in enumerate(sorted_users):
            # æ‰¾åˆ°ç”¨æˆ·æ‰€å±çš„ç»„
            user_group = "æœªçŸ¥"
            user_speaker = "æœªçŸ¥"
            for group in groups_mapping:
                for member in group.get('group_members', []):
                    if member['user_id'] == user_id:
                        user_group = group['group_key']
                        user_speaker = member['speaker']
                        break
                if user_group != "æœªçŸ¥":
                    break
            
            print(f"   {i+1:2d}. ç”¨æˆ· {user_id[:8]}... ({user_group}-{user_speaker}): {count:3d} æ¡è®°å½•")
        
        # æ¸…ç†è¿æ¥
        firebase_admin.delete_app(firebase_admin.get_app())
        print("âœ… Firebaseè¿æ¥å·²å…³é—­")
        
        return all_behavior_data
        
    except Exception as e:
        print(f"âŒ è·å–pageBehaviorLogsæ•°æ®å¤±è´¥: {e}")
        return []

def main():
    """ä¸»å‡½æ•°"""
    # æ–‡ä»¶è·¯å¾„
    mapping_file = "complete_groups_mapping.json"
    output_file = "all_groups_page_behavior_by_10s.csv"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(mapping_file):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {mapping_file}")
        return
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = PageBehaviorAnalyzer(mapping_file, output_file)
    
    # è·å–pageBehaviorLogsæ•°æ®
    behavior_data = get_page_behavior_logs()
    
    if not behavior_data:
        print("é”™è¯¯ï¼šæ²¡æœ‰è·å–åˆ°pageBehaviorLogsæ•°æ®")
        return
    
    try:
        # æ‰§è¡Œåˆ†æ
        result = analyzer.analyze_and_export(behavior_data)
        print(f"åˆ†æç»“æœ: {result}")
        
    except Exception as e:
        print(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

if __name__ == "__main__":
    main()
