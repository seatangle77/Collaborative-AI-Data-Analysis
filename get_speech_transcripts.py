"""
è·å–speech_transcripts_offlineæ•°æ®
æŒ‰group_idå’Œuser_idæ’åˆ—å¹¶å¯¼å‡ºä¸ºCSV
æ”¯æŒè·å–å…¨éƒ¨å°ç»„çš„è¯­éŸ³å†…å®¹
"""
import traceback
import json

import firebase_admin
from firebase_admin import credentials, firestore
import pandas as pd
from datetime import datetime, timedelta, timezone

from google.cloud.firestore_v1 import FieldFilter


def process_single_group(db, group_config):
    """å¤„ç†å•ä¸ªå°ç»„çš„è¯­éŸ³æ•°æ®"""
    group_key = group_config["group_key"]
    group_id = group_config["group_id"]
    base_time_str = group_config["base_time_str"]
    
    print(f"\nğŸ“– å¤„ç†å°ç»„: {group_key} (ID: {group_id})")
    print(f"   åŸºå‡†æ—¶é—´: {base_time_str}")
    
    # è·å–è¯¥å°ç»„çš„è¯­éŸ³æ•°æ®
    all_data = [doc.to_dict() for doc in db.collection("speech_transcripts_offline")
                .where(filter=FieldFilter("group_id", "==", group_id))
                .stream()]
    
    print(f"   è·å–åˆ° {len(all_data)} æ¡è¯­éŸ³è®°å½•")
    
    if not all_data:
        print(f"   âš ï¸  å°ç»„ {group_key} æ²¡æœ‰è¯­éŸ³æ•°æ®")
        return None
    
    # æŒ‰å¼€å§‹æ—¶é—´æ’åº
    all_data = sorted(all_data, key=lambda x: x.get("start"))
    
    # è§£æåŸºå‡†æ—¶é—´
    base_time = datetime.strptime(base_time_str, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)
    interval = 10  # ç§’
    num_intervals = 180  # 30åˆ†é’Ÿ
    
    # ç”ŸæˆåŒºé—´èµ·æ­¢æ—¶é—´
    intervals = [(base_time + timedelta(seconds=i * interval), base_time + timedelta(seconds=(i + 1) * interval))
                 for i in range(num_intervals)]
    
    # ç»Ÿè®¡ç»“æ„ï¼š{speaker: [æ¯ä¸ªåŒºé—´çš„å‘è¨€æ—¶é•¿]}
    speakers = set(d['speaker'] for d in all_data)
    result = {spk: [0.0] * num_intervals for spk in speakers}
    
    for d in all_data:
        s = datetime.fromisoformat(d['start'])
        e = datetime.fromisoformat(d['end'])
        spk = d['speaker']
        # è·³è¿‡ä¸åœ¨åŠå°æ—¶å†…çš„
        if e < base_time or s > base_time + timedelta(seconds=interval * num_intervals):
            continue
        # è®¡ç®—æ¯ä¸ªåŒºé—´çš„é‡å æ—¶é•¿
        for idx, (intv_start, intv_end) in enumerate(intervals):
            overlap_start = max(s, intv_start)
            overlap_end = min(e, intv_end)
            overlap = (overlap_end - overlap_start).total_seconds()
            if overlap > 0:
                result[spk][idx] += overlap
    
    # è½¬ä¸ºDataFrameå¹¶æ·»åŠ group_keyåˆ—
    df = pd.DataFrame(result).T
    df.columns = [
        f"{(i * interval) // 60:02d}:{(i * interval) % 60:02d}-{((i + 1) * interval) // 60:02d}:{((i + 1) * interval) % 60:02d}"
        for i in range(num_intervals)]
    df.index.name = "speaker"
    df.reset_index(inplace=True)
    df.insert(0, "group_key", group_key)
    
    # æ§åˆ¶æ•°æ®ç²¾åº¦ï¼Œå››èˆäº”å…¥åˆ°2ä½å°æ•°
    numeric_columns = df.select_dtypes(include=[float]).columns
    df[numeric_columns] = df[numeric_columns].round(2)
    
    return df


def get_speech_transcripts():
    """è·å–æ‰€æœ‰å°ç»„çš„è¯­éŸ³è½¬å½•æ•°æ®"""
    try:
        # è¯»å–å°ç»„é…ç½®
        print("ğŸ“‹ è¯»å–å°ç»„é…ç½®æ–‡ä»¶...")
        with open("all_groups_mapping.json", "r", encoding="utf-8") as f:
            config = json.load(f)
        
        groups = config["groups_mapping"]
        print(f"âœ… æ‰¾åˆ° {len(groups)} ä¸ªå°ç»„")
        
        # åˆå§‹åŒ–Firebaseåº”ç”¨
        cred = credentials.Certificate("firebase-key.json")
        firebase_admin.initialize_app(cred)
        
        print("âœ… Firebaseè¿æ¥æˆåŠŸï¼")
        
        # è·å–Firestoreå®¢æˆ·ç«¯
        db = firestore.client()
        
        # å¤„ç†æ‰€æœ‰å°ç»„
        all_groups_data = []
        
        for group_config in groups:
            try:
                group_df = process_single_group(db, group_config)
                if group_df is not None:
                    all_groups_data.append(group_df)
            except Exception as e:
                print(f"âŒ å¤„ç†å°ç»„ {group_config['group_key']} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        if not all_groups_data:
            print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•å°ç»„çš„æ•°æ®")
            return
        
        # åˆå¹¶æ‰€æœ‰å°ç»„æ•°æ®
        print(f"\nğŸ”„ åˆå¹¶ {len(all_groups_data)} ä¸ªå°ç»„çš„æ•°æ®...")
        final_df = pd.concat(all_groups_data, ignore_index=True)
        
        print(f"âœ… æœ€ç»ˆæ•°æ®å½¢çŠ¶: {final_df.shape}")
        print(f"   åŒ…å« {final_df['group_key'].nunique()} ä¸ªå°ç»„")
        print(f"   åŒ…å« {final_df['speaker'].nunique()} ä¸ªå‘è¨€è€…")
        
        # å¯¼å‡ºcsv
        output_filename = "all_groups_speaker_time_by_10s.csv"
        final_df.to_csv(output_filename, encoding="utf-8-sig", index=False)
        print(f"\nğŸ’¾ æ•°æ®å·²å¯¼å‡ºåˆ°: {output_filename}")
        
        # æ¸…ç†
        firebase_admin.delete_app(firebase_admin.get_app())
        print("\nâœ… è¿æ¥å·²å…³é—­")
        
    except Exception as e:
        print(f"âŒ è·å–æ•°æ®å¤±è´¥: {traceback.format_exc()}")


if __name__ == "__main__":
    print("å¼€å§‹è·å–æ‰€æœ‰å°ç»„çš„è¯­éŸ³è½¬å½•æ•°æ®...")
    get_speech_transcripts()
