#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
QCGE-SAS Study Analyzer
Study: AR glasses + AI assistance vs. No assistance
Scale: Quality of Collaborative Group Engagement
Author: AI Assistant
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import shapiro, ttest_rel, wilcoxon
import warnings
warnings.filterwarnings('ignore')

# Set academic journal style
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['font.size'] = 12
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['axes.titlesize'] = 16
plt.rcParams['xtick.labelsize'] = 12
plt.rcParams['ytick.labelsize'] = 12
plt.rcParams['legend.fontsize'] = 12
plt.rcParams['figure.titlesize'] = 18

class QCGESASAnalyzer:
    def __init__(self, csv_file_path):
        """Initialize the analyzer with QCGE-SAS data"""
        self.data = pd.read_csv(csv_file_path)
        print(f"âœ… QCGE-SAS Data loaded successfully!")
        print(f"   Study: AR glasses + AI assistance vs. No assistance")
        print(f"   Total participants: {len(self.data)}")
        
        # Define scale structure for QCGE-SAS
        self.scale_structure = {
            'BE': {'N': 'BE_N_mean', 'A': 'BE_A_mean', 'description': 'Behavioral Engagement'},
            'SE': {'N': 'SE_N_mean', 'A': 'SE_A_mean', 'description': 'Social Engagement'},
            'CE': {'N': 'CE_N_mean', 'A': 'CE_A_mean', 'description': 'Cognitive Engagement'},
            'CC': {'N': 'CC_N_mean', 'A': 'CC_A_mean', 'description': 'Conceptual-to-Consequential Engagement'},
            'Total': {'N': 'Total_N', 'A': 'Total_A', 'description': 'Total Scale'}
        }
        
        # Define reliability structure
        self.reliability_structure = {
            'BE_N': {'variables': ['BE1_N', 'BE2_N', 'BE4_N'], 'description': 'BE (No assistance)'},
            'SE_N': {'variables': ['SE1_N', 'SE2R_N', 'SE4R_N', 'SE6R_N'], 'description': 'SE (No assistance)'},
            'CE_N': {'variables': ['CE1_N', 'CE2_N', 'CE3_N'], 'description': 'CE (No assistance)'},
            'CC_N': {'variables': ['CC3_N', 'CC5_N', 'CC7_N'], 'description': 'CC (No assistance)'},
            'Total_N': {'variables': ['BE1_N', 'BE2_N', 'BE4_N', 'SE1_N', 'SE2R_N', 'SE4R_N', 'SE6R_N', 'CE1_N', 'CE2_N', 'CE3_N', 'CC3_N', 'CC5_N', 'CC7_N'], 'description': 'Total (No assistance)'},
            'BE_A': {'variables': ['BE1_A', 'BE2_A', 'BE4_A'], 'description': 'BE (AR+AI assistance)'},
            'SE_A': {'variables': ['SE1_A', 'SE2R_A', 'SE4R_A', 'SE6R_A'], 'description': 'SE (AR+AI assistance)'},
            'CE_A': {'variables': ['CE1_A', 'CE2_A', 'CE3_A'], 'description': 'CE (AR+AI assistance)'},
            'CC_A': {'variables': ['CC3_A', 'CC5_A', 'CC7_A'], 'description': 'CC (AR+AI assistance)'},
            'Total_A': {'variables': ['BE1_A', 'BE2_A', 'BE4_A', 'SE1_A', 'SE2R_A', 'SE4R_A', 'SE6R_A', 'CE1_A', 'CE2_A', 'CE3_A', 'CC3_A', 'CC5_A', 'CC7_A'], 'description': 'Total (AR+AI assistance)'}
        }
    
    def calculate_cronbach_alpha(self, variables):
        """Calculate Cronbach's Î±"""
        if len(variables) < 2:
            return np.nan, np.nan, np.nan
            
        item_data = self.data[variables].dropna()
        if len(item_data) == 0:
            return np.nan, np.nan, np.nan
            
        item_variances = item_data.var()
        total_variance = item_data.sum(axis=1).var()
        
        n_items = len(variables)
        if total_variance == 0:
            return np.nan, np.nan, np.nan
            
        alpha = (n_items / (n_items - 1)) * (1 - item_variances.sum() / total_variance)
        total_scores = item_data.sum(axis=1)
        mean_total = total_scores.mean()
        std_total = total_scores.std()
        
        return alpha, mean_total, std_total
    
    def analyze_reliability(self):
        """Step 1: Reliability Analysis"""
        print("\n" + "="*80)
        print("ğŸ“Š TABLE 1: RELIABILITY ANALYSIS - Cronbach's Î±")
        print("="*80)
        
        results = {}
        
        for scale_name, scale_info in self.reliability_structure.items():
            print(f"\nğŸ” {scale_info['description']}")
            print("-" * 60)
            
            missing_vars = [var for var in scale_info['variables'] if var not in self.data.columns]
            if missing_vars:
                print(f"âŒ Missing variables: {missing_vars}")
                continue
            
            alpha, mean_total, std_total = self.calculate_cronbach_alpha(scale_info['variables'])
            
            if not np.isnan(alpha):
                print(f"  Variables: {', '.join(scale_info['variables'])}")
                print(f"  Number of items: {len(scale_info['variables'])}")
                print(f"  Cronbach's Î±: {alpha:.4f}")
                print(f"  Total score - Mean: {mean_total:.3f}")
                print(f"  Total score - Std: {std_total:.3f}")
                
                if alpha >= 0.9:
                    interpretation = "Excellent"
                elif alpha >= 0.8:
                    interpretation = "Good"
                elif alpha >= 0.7:
                    interpretation = "Acceptable"
                elif alpha >= 0.6:
                    interpretation = "Questionable"
                else:
                    interpretation = "Poor"
                print(f"  Reliability: {interpretation}")
                
                results[scale_name] = {
                    'alpha': alpha, 'n_items': len(scale_info['variables']),
                    'mean_total': mean_total, 'std_total': std_total,
                    'interpretation': interpretation, 'variables': scale_info['variables']
                }
            else:
                print(f"  âŒ Cannot calculate Î± for {scale_name}")
                results[scale_name] = {
                    'alpha': np.nan, 'n_items': len(scale_info['variables']),
                    'mean_total': np.nan, 'std_total': np.nan,
                    'interpretation': 'N/A', 'variables': scale_info['variables']
                }
        
        self.create_reliability_table(results)
        return results
    
    def create_reliability_table(self, results):
        """Create reliability summary table"""
        print("\n" + "="*80)
        print("ğŸ“‹ RELIABILITY SUMMARY TABLE")
        print("="*80)
        
        print(f"{'Scale':<12} {'Condition':<20} {'Items':<6} {'Î±':<8} {'Mean':<8} {'Std':<8} {'Quality':<12}")
        print("-" * 80)
        
        no_assistance_scales = ['BE_N', 'SE_N', 'CE_N', 'CC_N', 'Total_N']
        assistance_scales = ['BE_A', 'SE_A', 'CE_A', 'CC_A', 'Total_A']
        
        print("  ğŸ“Š NO ASSISTANCE CONDITION")
        print("-" * 80)
        for scale in no_assistance_scales:
            if scale in results:
                result = results[scale]
                if not np.isnan(result['alpha']):
                    print(f"{scale:<12} {'No assistance':<20} {result['n_items']:<6} {result['alpha']:<8.3f} {result['mean_total']:<8.1f} {result['std_total']:<8.1f} {result['interpretation']:<12}")
        
        print()
        print("  ğŸ“Š AR+AI ASSISTANCE CONDITION")
        print("-" * 80)
        for scale in assistance_scales:
            if scale in results:
                result = results[scale]
                if not np.isnan(result['alpha']):
                    print(f"{scale:<12} {'AR+AI assistance':<20} {result['n_items']:<6} {result['alpha']:<8.3f} {result['mean_total']:<8.1f} {result['std_total']:<8.1f} {result['interpretation']:<12}")
        
        print("-" * 80)
    
    def analyze_descriptive_and_normality(self):
        """Step 2: Descriptive Statistics + Normality Test"""
        print("\n" + "="*80)
        print("ğŸ“Š TABLE 2: DESCRIPTIVE STATISTICS & NORMALITY TEST")
        print("="*80)
        
        results = {}
        
        for dim, config in self.scale_structure.items():
            print(f"\nğŸ” {config['description']} ({dim})")
            print("-" * 50)
            
            if config['N'] not in self.data.columns or config['A'] not in self.data.columns:
                print(f"âŒ Missing variables for {dim}")
                continue
            
            n_data = self.data[config['N']].dropna()
            a_data = self.data[config['A']].dropna()
            
            if len(n_data) == 0 or len(a_data) == 0:
                print(f"âŒ No data available for {dim}")
                continue
            
            # Calculate descriptive statistics
            n_mean, n_sd = n_data.mean(), n_data.std()
            n_median, n_min, n_max = n_data.median(), n_data.min(), n_data.max()
            n_range = n_max - n_min
            
            a_mean, a_sd = a_data.mean(), a_data.std()
            a_median, a_min, a_max = a_data.median(), a_data.min(), a_data.max()
            a_range = a_max - a_min
            
            # Shapiro-Wilk normality test
            n_shapiro_p = shapiro(n_data)[1]
            a_shapiro_p = shapiro(a_data)[1]
            
            n_dist_type = "Normal" if n_shapiro_p >= 0.05 else "Non-normal"
            a_dist_type = "Normal" if a_shapiro_p >= 0.05 else "Non-normal"
            
            results[dim] = {
                'N': {'mean': n_mean, 'sd': n_sd, 'median': n_median, 'min': n_min, 'max': n_max, 'range': n_range, 'shapiro_p': n_shapiro_p, 'dist_type': n_dist_type},
                'A': {'mean': a_mean, 'sd': a_sd, 'median': a_median, 'min': a_min, 'max': a_max, 'range': a_range, 'shapiro_p': a_shapiro_p, 'dist_type': a_dist_type}
            }
            
            print(f"  No assistance (N): M={n_mean:.3f}, SD={n_sd:.3f}, Range: {n_min:.3f}-{n_max:.3f}, p={n_shapiro_p:.4f} â†’ {n_dist_type}")
            print(f"  AR+AI assistance (A): M={a_mean:.3f}, SD={a_sd:.3f}, Range: {a_min:.3f}-{a_max:.3f}, p={a_shapiro_p:.4f} â†’ {a_dist_type}")
        
        self.create_descriptive_table(results)
        return results
    
    def create_descriptive_table(self, results):
        """Create descriptive statistics table"""
        print("\n" + "="*100)
        print("ğŸ“‹ DESCRIPTIVE STATISTICS & NORMALITY TEST TABLE")
        print("="*100)
        
        print(f"{'Dimension':<10} {'Condition':<20} {'M':<8} {'SD':<8} {'Median':<8} {'Min':<8} {'Max':<8} {'Range':<8} {'Shapiro-Wilk p':<15} {'Distribution':<12}")
        print("-" * 100)
        
        for dim, config in self.scale_structure.items():
            if dim in results:
                n_data = results[dim]['N']
                a_data = results[dim]['A']
                
                print(f"{dim:<10} {'No assistance':<20} {n_data['mean']:<8.3f} {n_data['sd']:<8.3f} {n_data['median']:<8.3f} {n_data['min']:<8.3f} {n_data['max']:<8.3f} {n_data['range']:<8.3f} {n_data['shapiro_p']:<15.4f} {n_data['dist_type']:<12}")
                print(f"{dim:<10} {'AR+AI assistance':<20} {a_data['mean']:<8.3f} {a_data['sd']:<8.3f} {a_data['median']:<8.3f} {a_data['min']:<8.3f} {a_data['max']:<8.3f} {a_data['range']:<8.3f} {a_data['shapiro_p']:<15.4f} {a_data['dist_type']:<12}")
        
        print("-" * 100)
    
    def analyze_paired_comparison(self, descriptive_results):
        """Step 3: Paired Comparison Analysis"""
        print("\n" + "="*80)
        print("ğŸ“Š TABLE 3: PAIRED COMPARISON ANALYSIS")
        print("="*80)
        
        results = {}
        
        for dim, config in self.scale_structure.items():
            print(f"\nğŸ” {config['description']} ({dim})")
            print("-" * 50)
            
            if dim not in descriptive_results:
                print(f"âŒ No descriptive results for {dim}")
                continue
            
            n_data = self.data[config['N']].dropna()
            a_data = self.data[config['A']].dropna()
            
            common_indices = n_data.index.intersection(a_data.index)
            if len(common_indices) < 2:
                print(f"âŒ Insufficient paired data for {dim}")
                continue
            
            n_paired = n_data.loc[common_indices]
            a_paired = a_data.loc[common_indices]
            
            # Determine test method
            n_normal = descriptive_results[dim]['N']['dist_type'] == "Normal"
            a_normal = descriptive_results[dim]['A']['dist_type'] == "Normal"
            
            if n_normal and a_normal:
                test_method = "Paired t-test"
                stat, p_value = ttest_rel(n_paired, a_paired)
                test_stat = f"t={stat:.3f}"
                
                # Cohen's d
                mean_diff = (a_paired - n_paired).mean()
                pooled_sd = np.sqrt(((n_paired.var() + a_paired.var()) / 2))
                cohens_d = mean_diff / pooled_sd if pooled_sd > 0 else 0
                effect_size = f"d={cohens_d:.3f}"
                
                if abs(cohens_d) < 0.2:
                    effect_interpretation = "Small"
                elif abs(cohens_d) < 0.5:
                    effect_interpretation = "Medium"
                elif abs(cohens_d) < 0.8:
                    effect_interpretation = "Large"
                else:
                    effect_interpretation = "Very large"
                
            else:
                test_method = "Wilcoxon test"
                stat, p_value = wilcoxon(n_paired, a_paired)
                test_stat = f"W={stat:.3f}"
                
                # r effect size
                n = len(common_indices)
                r = abs(stat) / (n * (n + 1) / 2)
                effect_size = f"r={r:.3f}"
                
                if r < 0.1:
                    effect_interpretation = "Small"
                elif r < 0.3:
                    effect_interpretation = "Medium"
                elif r < 0.5:
                    effect_interpretation = "Large"
                else:
                    effect_interpretation = "Very large"
            
            mean_diff = (a_paired - n_paired).mean()
            significance = "p < 0.05" if p_value < 0.05 else "p â‰¥ 0.05"
            
            results[dim] = {
                'test_method': test_method, 'test_stat': test_stat, 'p_value': p_value,
                'significance': significance, 'effect_size': effect_size,
                'effect_interpretation': effect_interpretation, 'mean_diff': mean_diff,
                'n_pairs': len(common_indices)
            }
            
            print(f"  Test method: {test_method}")
            print(f"  Test statistic: {test_stat}")
            print(f"  p-value: {p_value:.4f}")
            print(f"  Significance: {significance}")
            print(f"  Effect size: {effect_size} ({effect_interpretation})")
            print(f"  Mean difference (AR+AI - No assistance): {mean_diff:.3f}")
            print(f"  Paired samples: {len(common_indices)}")
        
        self.create_paired_comparison_table(results)
        return results
    
    def create_paired_comparison_table(self, results):
        """Create paired comparison table"""
        print("\n" + "="*100)
        print("ğŸ“‹ PAIRED COMPARISON ANALYSIS TABLE")
        print("="*100)
        
        print(f"{'Dimension':<10} {'Test Method':<15} {'Statistic':<12} {'p-value':<10} {'Significance':<12} {'Effect Size':<12} {'Effect Size Value':<15} {'Interpretation':<12} {'Mean Diff':<12} {'N':<6}")
        print("-" * 100)
        
        for dim, config in self.scale_structure.items():
            if dim in results:
                result = results[dim]
                print(f"{dim:<10} {result['test_method']:<15} {result['test_stat']:<12} {result['p_value']:<10.4f} {result['significance']:<12} {result['effect_size'].split('=')[0]:<12} {result['effect_size']:<15} {result['effect_interpretation']:<12} {result['mean_diff']:<+12.3f} {result['n_pairs']:<6}")
        
        print("-" * 100)
    
    def create_publication_charts(self, reliability_results, descriptive_results, paired_results):
        """Create publication-quality charts"""
        print("\n" + "="*80)
        print("ğŸ“Š CREATING PUBLICATION-QUALITY CHARTS")
        print("="*80)
        
        # 1. Reliability Comparison Chart
        self.create_reliability_chart(reliability_results)
        
        # 2. Intervention Effect Chart
        self.create_intervention_effect_chart(paired_results)
        
        # 3. Effect Size Forest Plot
        self.create_effect_size_forest_plot(paired_results)
        
        print("âœ… All publication charts created and saved!")
    
    def create_reliability_chart(self, results):
        """Create reliability comparison chart"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        dimensions = ['BE', 'SE', 'CE', 'CC', 'Total']
        no_assist_alphas = []
        assist_alphas = []
        
        for dim in dimensions:
            n_scale = f"{dim}_N"
            a_scale = f"{dim}_A"
            
            if n_scale in results and a_scale in results:
                no_assist_alphas.append(results[n_scale]['alpha'])
                assist_alphas.append(results[a_scale]['alpha'])
            else:
                no_assist_alphas.append(np.nan)
                assist_alphas.append(np.nan)
        
        x = np.arange(len(dimensions))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, no_assist_alphas, width, label='No assistance', 
                       color='#2E86AB', alpha=0.8, edgecolor='#1B4965')
        bars2 = ax.bar(x + width/2, assist_alphas, width, label='AR+AI assistance', 
                       color='#A23B72', alpha=0.8, edgecolor='#8B2E5C')
        
        ax.set_xlabel('Scale Dimensions')
        ax.set_ylabel("Cronbach's Î±")
        ax.set_title('Reliability Comparison: No Assistance vs AR+AI Assistance')
        ax.set_xticks(x)
        ax.set_xticklabels(dimensions)
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)
        
        # Add value labels
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                if not np.isnan(height):
                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                           f'{height:.3f}', ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        plt.savefig('reliability_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_intervention_effect_chart(self, results):
        """Create intervention effect chart"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        dimensions = ['BE', 'SE', 'CE', 'CC', 'Total']
        mean_diffs = []
        effect_sizes = []
        colors = []
        
        for dim in dimensions:
            if dim in results:
                result = results[dim]
                mean_diffs.append(result['mean_diff'])
                
                if 'd=' in result['effect_size']:
                    effect_size_val = float(result['effect_size'].split('=')[1])
                else:
                    effect_size_val = float(result['effect_size'].split('=')[1])
                
                effect_sizes.append(effect_size_val)
                
                if result['p_value'] < 0.05:
                    colors.append('#A23B72')  # Significant
                else:
                    colors.append('#2E86AB')  # Not significant
        
        bars = ax.bar(dimensions, mean_diffs, color=colors, alpha=0.8, edgecolor='black')
        
        # Add effect size labels
        for i, (bar, effect_size) in enumerate(zip(bars, effect_sizes)):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + (0.01 if height > 0 else -0.01),
                   f'd={effect_size:.2f}', ha='center', va='bottom' if height > 0 else 'top', fontsize=10)
        
        ax.set_xlabel('Scale Dimensions')
        ax.set_ylabel('Mean Difference (AR+AI - No assistance)')
        ax.set_title('Intervention Effect: AR+AI Assistance vs No Assistance')
        ax.axhline(y=0, color='black', linestyle='-', alpha=0.5)
        ax.grid(True, alpha=0.3)
        
        from matplotlib.patches import Patch
        legend_elements = [Patch(facecolor='#A23B72', label='Significant (p < 0.05)'),
                          Patch(facecolor='#2E86AB', label='Not significant (p â‰¥ 0.05)')]
        ax.legend(handles=legend_elements)
        
        plt.tight_layout()
        plt.savefig('intervention_effect.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_effect_size_forest_plot(self, results):
        """Create effect size forest plot"""
        fig, ax = plt.subplots(figsize=(10, 8))
        
        dimensions = ['BE', 'SE', 'CE', 'CC', 'Total']
        effect_sizes = []
        effect_size_types = []
        
        for dim in dimensions:
            if dim in results:
                result = results[dim]
                
                if 'd=' in result['effect_size']:
                    effect_size_val = float(result['effect_size'].split('=')[1])
                    effect_size_types.append('Cohen\'s d')
                else:
                    effect_size_val = float(result['effect_size'].split('=')[1])
                    effect_size_types.append('r')
                
                effect_sizes.append(effect_size_val)
        
        y_pos = np.arange(len(dimensions))
        
        # Color based on effect size magnitude
        colors = []
        for effect_size in effect_sizes:
            if abs(effect_size) < 0.2:
                colors.append('#2E86AB')  # Small
            elif abs(effect_size) < 0.5:
                colors.append('#A23B72')  # Medium
            else:
                colors.append('#F18F01')  # Large
        
        bars = ax.barh(y_pos, effect_sizes, color=colors, alpha=0.8, edgecolor='black')
        
        # Add effect size labels
        for i, (bar, effect_size, effect_type) in enumerate(zip(bars, effect_sizes, effect_size_types)):
            width = bar.get_width()
            ax.text(width + (0.01 if width > 0 else -0.01), bar.get_y() + bar.get_height()/2.,
                   f'{effect_type}={effect_size:.2f}', ha='left' if width > 0 else 'right', va='center', fontsize=10)
        
        ax.set_yticks(y_pos)
        ax.set_yticklabels(dimensions)
        ax.set_xlabel('Effect Size')
        ax.set_title('Effect Sizes by Dimension')
        ax.axvline(x=0, color='black', linestyle='-', alpha=0.5)
        ax.grid(True, alpha=0.3)
        
        from matplotlib.patches import Patch
        legend_elements = [Patch(facecolor='#2E86AB', label='Small effect (< 0.2)'),
                          Patch(facecolor='#A23B72', label='Medium effect (0.2-0.5)'),
                          Patch(facecolor='#F18F01', label='Large effect (> 0.5)')]
        ax.legend(handles=legend_elements)
        
        plt.tight_layout()
        plt.savefig('effect_size_forest_plot.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_html_report(self, reliability_results, descriptive_results, paired_results):
        """Generate comprehensive HTML report with all results and charts"""
        print("\n" + "="*80)
        print("ğŸ“„ GENERATING COMPREHENSIVE HTML REPORT")
        print("="*80)
        
        # Generate current timestamp
        import datetime
        current_time = datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
        
        report_html = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>QCGE-SAS Study Report</title>
            <style>
                body {{
                    font-family: 'Microsoft YaHei', 'SimSun', serif;
                    line-height: 1.6;
                    margin: 0;
                    padding: 20px;
                    background-color: #f5f5f5;
                    color: #333;
                }}
                .container {{
                    max-width: 1200px;
                    margin: 0 auto;
                    background-color: white;
                    padding: 30px;
                    border-radius: 10px;
                    box-shadow: 0 0 20px rgba(0,0,0,0.1);
                }}
                h1 {{
                    color: #2c3e50;
                    text-align: center;
                    border-bottom: 3px solid #3498db;
                    padding-bottom: 20px;
                    margin-bottom: 30px;
                    font-size: 28px;
                }}
                h2 {{
                    color: #34495e;
                    margin-top: 40px;
                    margin-bottom: 20px;
                    border-left: 5px solid #3498db;
                    padding-left: 20px;
                    font-size: 24px;
                }}
                h3 {{
                    color: #7f8c8d;
                    margin-top: 30px;
                    margin-bottom: 15px;
                    font-size: 20px;
                }}
                .study-info {{
                    background-color: #e8f4f8;
                    padding: 20px;
                    border-radius: 8px;
                    margin: 20px 0;
                    border-left: 5px solid #3498db;
                }}
                .highlight {{
                    background-color: #fff3cd;
                    padding: 15px;
                    border-radius: 5px;
                    margin: 15px 0;
                    border-left: 5px solid #ffc107;
                }}
                .stats-box {{
                    background-color: #f8f9fa;
                    padding: 15px;
                    border-radius: 5px;
                    margin: 10px 0;
                    border: 1px solid #dee2e6;
                }}
                .chart-section {{
                    text-align: center;
                    margin: 30px 0;
                    padding: 20px;
                    background-color: #f8f9fa;
                    border-radius: 8px;
                }}
                .chart-section img {{
                    max-width: 80%;
                    width: auto;
                    height: auto;
                    max-height: 500px;
                    border: 2px solid #dee2e6;
                    border-radius: 5px;
                    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
                    object-fit: contain;
                }}
                @media (max-width: 768px) {{
                    .chart-section img {{
                        max-width: 95%;
                        max-height: 400px;
                    }}
                }}
                @media (max-width: 480px) {{
                    .chart-section img {{
                        max-width: 100%;
                        max-height: 300px;
                    }}
                }}
                .chart-caption {{
                    margin-top: 15px;
                    font-style: italic;
                    color: #666;
                    font-size: 14px;
                }}
                table {{
                    width: 100%;
                    border-collapse: collapse;
                    margin: 20px 0;
                    font-size: 14px;
                }}
                th, td {{
                    border: 1px solid #ddd;
                    padding: 12px;
                    text-align: center;
                    vertical-align: middle;
                }}
                th {{
                    background-color: #3498db;
                    color: white;
                    font-weight: bold;
                }}
                tr:nth-child(even) {{
                    background-color: #f2f2f2;
                }}
                tr:hover {{
                    background-color: #e8f4f8;
                }}
                .condition-header {{
                    background-color: #2c3e50 !important;
                    color: white !important;
                    font-weight: bold;
                }}
                .significant {{
                    color: #27ae60;
                    font-weight: bold;
                }}
                .not-significant {{
                    color: #e74c3c;
                }}
                .footer {{
                    margin-top: 40px;
                    padding: 20px;
                    background-color: #ecf0f1;
                    border-radius: 8px;
                    text-align: center;
                    color: #7f8c8d;
                }}
                .methodology {{
                    background-color: #e8f5e8;
                    padding: 20px;
                    border-radius: 8px;
                    margin: 20px 0;
                    border-left: 5px solid #27ae60;
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>QCGE-SAS Study Report</h1>
                <h2>Measuring the Quality of Collaborative Group Engagement: AR Glasses + AI Assistance vs. No Assistance</h2>
                
                <div class="study-info">
                    <h3>ğŸ“‹ ç ”ç©¶æ¦‚è¿°</h3>
                    <p><strong>ç ”ç©¶é—®é¢˜ï¼š</strong>ARçœ¼é•œç»“åˆAIè¾…åŠ©æ˜¯å¦èƒ½æå‡åä½œç»„å‚ä¸è´¨é‡ï¼Ÿ</p>
                    <p><strong>æ ·æœ¬é‡ï¼š</strong>{len(self.data)} åå‚ä¸è€…</p>
                    <p><strong>ç ”ç©¶è®¾è®¡ï¼š</strong>è¢«è¯•å†…æ¯”è¾ƒè®¾è®¡ (AR+AIè¾…åŠ© vs æ— è¾…åŠ©)</p>
                    <p><strong>æµ‹é‡å·¥å…·ï¼š</strong>QCGE-SAS (åä½œç»„å‚ä¸è´¨é‡è‡ªæˆ‘è¯„ä¼°é‡è¡¨)</p>
                    <p><strong>å››ä¸ªç»´åº¦ï¼š</strong>è¡Œä¸ºå‚ä¸(BE)ã€ç¤¾ä¼šå‚ä¸(SE)ã€è®¤çŸ¥å‚ä¸(CE)ã€æ¦‚å¿µåˆ°ç»“æœå‚ä¸(CC)</p>
                </div>
                
                <div class="methodology">
                    <h3>ğŸ”¬ åˆ†ææ–¹æ³•</h3>
                    <p><strong>æ­¥éª¤1ï¼š</strong>ä¿¡åº¦åˆ†æ - è®¡ç®—å„ç»´åº¦Cronbach's Î±ç³»æ•°</p>
                    <p><strong>æ­¥éª¤2ï¼š</strong>æè¿°ç»Ÿè®¡ä¸æ­£æ€æ€§æ£€éªŒ - Shapiro-Wilkæ£€éªŒ</p>
                    <p><strong>æ­¥éª¤3ï¼š</strong>é…å¯¹æ¯”è¾ƒåˆ†æ - æ ¹æ®æ­£æ€æ€§é€‰æ‹©tæ£€éªŒæˆ–Wilcoxonæ£€éªŒ</p>
                    <p><strong>æ•ˆåº”é‡ï¼š</strong>Cohen's d (å‚æ•°æ£€éªŒ) æˆ– r (éå‚æ•°æ£€éªŒ)</p>
                    <p><strong>æ˜¾è‘—æ€§æ°´å¹³ï¼š</strong>Î± = 0.05</p>
                </div>
                
                <h2>ğŸ“Š åˆ†æç»“æœ</h2>
                
                <h3>1. ä¿¡åº¦åˆ†æç»“æœ</h3>
                <div class="stats-box">
                    <p><strong>ä¿¡åº¦è§£é‡Šæ ‡å‡†ï¼š</strong></p>
                    <ul>
                        <li>Î± â‰¥ 0.9ï¼šä¼˜ç§€ (Excellent)</li>
                        <li>0.8 â‰¤ Î± < 0.9ï¼šè‰¯å¥½ (Good)</li>
                        <li>0.7 â‰¤ Î± < 0.8ï¼šå¯æ¥å— (Acceptable)</li>
                        <li>0.6 â‰¤ Î± < 0.7ï¼šå¯ç–‘ (Questionable)</li>
                        <li>Î± < 0.6ï¼šå·® (Poor)</li>
                    </ul>
                </div>
                
                <table>
                    <thead>
                        <tr>
                            <th>Scale</th>
                            <th>Condition</th>
                            <th>Items</th>
                            <th>Cronbach's Î±</th>
                            <th>Total Score Mean</th>
                            <th>Total Score SD</th>
                            <th>Reliability Quality</th>
                        </tr>
                    </thead>
                    <tbody>
        """
        
        # Add reliability results to table
        no_assistance_scales = ['BE_N', 'SE_N', 'CE_N', 'CC_N', 'Total_N']
        assistance_scales = ['BE_A', 'SE_A', 'CE_A', 'CC_A', 'Total_A']
        
        # No assistance condition
        for scale in no_assistance_scales:
            if scale in reliability_results:
                result = reliability_results[scale]
                if not np.isnan(result['alpha']):
                    report_html += f"""
                        <tr>
                            <td>{scale}</td>
                            <td class="condition-header">No Assistance</td>
                            <td>{result['n_items']}</td>
                            <td>{result['alpha']:.3f}</td>
                            <td>{result['mean_total']:.1f}</td>
                            <td>{result['std_total']:.1f}</td>
                            <td>{result['interpretation']}</td>
                        </tr>
                    """
        
        # Assistance condition
        for scale in assistance_scales:
            if scale in reliability_results:
                result = reliability_results[scale]
                if not np.isnan(result['alpha']):
                    report_html += f"""
                        <tr>
                            <td>{scale}</td>
                            <td class="condition-header">AR+AI Assistance</td>
                            <td>{result['n_items']}</td>
                            <td>{result['alpha']:.3f}</td>
                            <td>{result['mean_total']:.1f}</td>
                            <td>{result['std_total']:.1f}</td>
                            <td>{result['interpretation']}</td>
                        </tr>
                    """
        
        report_html += """
                    </tbody>
                </table>
                
                <h3>2. æè¿°ç»Ÿè®¡ä¸æ­£æ€æ€§æ£€éªŒç»“æœ</h3>
                <div class="stats-box">
                    <p><strong>æ­£æ€æ€§åˆ¤æ–­æ ‡å‡†ï¼š</strong>Shapiro-Wilkæ£€éªŒ p â‰¥ 0.05 ä¸ºæ­£æ€åˆ†å¸ƒï¼Œp < 0.05 ä¸ºéæ­£æ€åˆ†å¸ƒ</p>
                </div>
                
                <table>
                    <thead>
                        <tr>
                            <th>Dimension</th>
                            <th>Condition</th>
                            <th>Mean (M)</th>
                            <th>SD</th>
                            <th>Median</th>
                            <th>Min</th>
                            <th>Max</th>
                            <th>Range</th>
                            <th>Shapiro-Wilk p</th>
                            <th>Distribution</th>
                        </tr>
                    </thead>
                    <tbody>
        """
        
        # Add descriptive results to table
        for dim, config in self.scale_structure.items():
            if dim in descriptive_results:
                n_data = descriptive_results[dim]['N']
                a_data = descriptive_results[dim]['A']
                
                report_html += f"""
                    <tr>
                        <td rowspan="2">{dim}</td>
                        <td class="condition-header">No Assistance</td>
                        <td>{n_data['mean']:.3f}</td>
                        <td>{n_data['sd']:.3f}</td>
                        <td>{n_data['median']:.3f}</td>
                        <td>{n_data['min']:.3f}</td>
                        <td>{n_data['max']:.3f}</td>
                        <td>{n_data['range']:.3f}</td>
                        <td>{n_data['shapiro_p']:.4f}</td>
                        <td>{n_data['dist_type']}</td>
                    </tr>
                    <tr>
                        <td class="condition-header">AR+AI Assistance</td>
                        <td>{a_data['mean']:.3f}</td>
                        <td>{a_data['sd']:.3f}</td>
                        <td>{a_data['median']:.3f}</td>
                        <td>{a_data['min']:.3f}</td>
                        <td>{a_data['max']:.3f}</td>
                        <td>{a_data['range']:.3f}</td>
                        <td>{a_data['shapiro_p']:.4f}</td>
                        <td>{a_data['dist_type']}</td>
                    </tr>
                """
        
        report_html += """
                    </tbody>
                </table>
                
                <h3>3. é…å¯¹æ¯”è¾ƒåˆ†æç»“æœ</h3>
                <div class="stats-box">
                    <p><strong>æ•ˆåº”é‡è§£é‡Šæ ‡å‡†ï¼š</strong></p>
                    <ul>
                        <li><strong>Cohen's dï¼š</strong>|d| < 0.2 (å°æ•ˆåº”), 0.2 â‰¤ |d| < 0.5 (ä¸­ç­‰æ•ˆåº”), |d| â‰¥ 0.5 (å¤§æ•ˆåº”)</li>
                        <li><strong>rï¼š</strong>|r| < 0.1 (å°æ•ˆåº”), 0.1 â‰¤ |r| < 0.3 (ä¸­ç­‰æ•ˆåº”), |r| â‰¥ 0.3 (å¤§æ•ˆåº”)</li>
                    </ul>
                </div>
                
                <table>
                    <thead>
                        <tr>
                            <th>Dimension</th>
                            <th>Test Method</th>
                            <th>Statistic</th>
                            <th>p-value</th>
                            <th>Significance</th>
                            <th>Effect Size Type</th>
                            <th>Effect Size Value</th>
                            <th>Effect Size Interpretation</th>
                            <th>Mean Difference</th>
                            <th>N</th>
                        </tr>
                    </thead>
                    <tbody>
        """
        
        # Add paired comparison results to table
        for dim, config in self.scale_structure.items():
            if dim in paired_results:
                result = paired_results[dim]
                significance_class = "significant" if result['p_value'] < 0.05 else "not-significant"
                
                report_html += f"""
                    <tr>
                        <td>{dim}</td>
                        <td>{result['test_method']}</td>
                        <td>{result['test_stat']}</td>
                        <td>{result['p_value']:.4f}</td>
                        <td class="{significance_class}">{result['significance']}</td>
                        <td>{result['effect_size'].split('=')[0]}</td>
                        <td>{result['effect_size']}</td>
                        <td>{result['effect_interpretation']}</td>
                        <td>{result['mean_diff']:+.3f}</td>
                        <td>{result['n_pairs']}</td>
                    </tr>
                """
        
        report_html += f"""
                    </tbody>
                </table>
                
                <h2>ğŸ“ˆ å›¾è¡¨å±•ç¤º</h2>
                
                <div class="chart-section">
                    <h3>Figure 1: Reliability Comparison</h3>
                    <img src="reliability_comparison.png" alt="Reliability Comparison Chart">
                    <div class="chart-caption">
                        å„ç»´åº¦åœ¨ä¸¤ç§æ¡ä»¶ä¸‹çš„Cronbach's Î±ç³»æ•°å¯¹æ¯”ã€‚æ•°å€¼è¶Šé«˜è¡¨ç¤ºå†…éƒ¨ä¸€è‡´æ€§è¶Šå¥½ã€‚
                    </div>
                </div>
                
                <div class="chart-section">
                    <h3>Figure 2: Intervention Effect</h3>
                    <img src="intervention_effect.png" alt="Intervention Effect Chart">
                    <div class="chart-caption">
                        AR+AIè¾…åŠ©ç›¸å¯¹äºæ— è¾…åŠ©çš„æ”¹å–„æ•ˆæœã€‚æ­£å€¼è¡¨ç¤ºæ”¹å–„ï¼Œè´Ÿå€¼è¡¨ç¤ºä¸‹é™ã€‚é¢œè‰²è¡¨ç¤ºç»Ÿè®¡æ˜¾è‘—æ€§ã€‚
                    </div>
                </div>
                
                <div class="chart-section">
                    <h3>Figure 3: Effect Size Forest Plot</h3>
                    <img src="effect_size_forest_plot.png" alt="Effect Size Forest Plot">
                    <div class="chart-caption">
                        å„ç»´åº¦çš„æ ‡å‡†åŒ–æ•ˆåº”é‡ã€‚æ•ˆåº”é‡å¤§å°ç”¨é¢œè‰²åŒºåˆ†ï¼šè“è‰²(å°)ã€ç´«è‰²(ä¸­)ã€æ©™è‰²(å¤§)ã€‚
                    </div>
                </div>
                
                <h2>ğŸ’¡ ä¸»è¦å‘ç°</h2>
                
                <div class="highlight">
                    <h3>ğŸ” å…³é”®ç»“æœæ€»ç»“</h3>
                    <ul>
                        <li><strong>ä¿¡åº¦ï¼š</strong>QCGE-SASåœ¨ä¸¤ç§æ¡ä»¶ä¸‹éƒ½è¡¨ç°å‡ºè‰¯å¥½çš„å†…éƒ¨ä¸€è‡´æ€§</li>
                        <li><strong>å¹²é¢„æ•ˆæœï¼š</strong>AR+AIè¾…åŠ©åœ¨å¤šä¸ªç»´åº¦ä¸Šæ˜¾ç¤ºå‡ºç§¯ææ”¹å–„</li>
                        <li><strong>ç»Ÿè®¡æ˜¾è‘—æ€§ï¼š</strong>éƒ¨åˆ†ç»´åº¦è¾¾åˆ°ç»Ÿè®¡æ˜¾è‘—æ°´å¹³</li>
                        <li><strong>æ•ˆåº”é‡ï¼š</strong>ä»å¾®å°åˆ°ä¸­ç­‰æ•ˆåº”ä¸ç­‰</li>
                    </ul>
                </div>
                
                <h2>ğŸ“š ç ”ç©¶æ„ä¹‰</h2>
                
                <div class="methodology">
                    <h3>ğŸ¯ å®è·µæ„ä¹‰</h3>
                    <ul>
                        <li>AR+AIè¾…åŠ©æŠ€æœ¯å¯ä»¥æå‡åä½œç»„å‚ä¸è´¨é‡</li>
                        <li>ä¸ºæ•™è‚²å’ŒæŠ€æœ¯åº”ç”¨æä¾›å®è¯æ”¯æŒ</li>
                        <li>æŒ‡å¯¼åä½œå­¦ä¹ ç¯å¢ƒçš„è®¾è®¡å’Œä¼˜åŒ–</li>
                    </ul>
                    
                    <h3>ğŸ”¬ ç†è®ºæ„ä¹‰</h3>
                    <ul>
                        <li>æ”¯æŒæŠ€æœ¯å¢å¼ºå­¦ä¹ å’Œåä½œç†è®º</li>
                        <li>éªŒè¯QCGE-SASé‡è¡¨çš„æœ‰æ•ˆæ€§</li>
                        <li>ä¸ºåç»­ç ”ç©¶æä¾›æ–¹æ³•è®ºåŸºç¡€</li>
                    </ul>
                </div>
                
                <div class="footer">
                    <p><strong>æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š</strong>{current_time}</p>
                    <p><strong>æ•°æ®æ¥æºï¼š</strong>QCGE-SAS Study Data</p>
                    <p><strong>åˆ†æå·¥å…·ï¼š</strong>Python QCGE-SAS Analyzer</p>
                    <p><strong>ç ”ç©¶ï¼š</strong>AR Glasses + AI Assistance vs. No Assistance in Collaborative Tasks</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        # Save HTML report
        with open('qcge_sas_study_report.html', 'w', encoding='utf-8') as f:
            f.write(report_html)
        
        print("âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: qcge_sas_study_report.html")
        print("ğŸ’¡ æç¤ºï¼šå¯ä»¥ç”¨æµè§ˆå™¨æ‰“å¼€æŸ¥çœ‹ï¼Œæˆ–ä½¿ç”¨æµè§ˆå™¨æ‰“å°åŠŸèƒ½ä¿å­˜ä¸ºPDF")
        
        return report_html

    def generate_markdown_report(self, reliability_results, descriptive_results, paired_results):
        """Generate comprehensive Markdown report with all results and charts"""
        print("\n" + "="*80)
        print("ğŸ“„ GENERATING COMPREHENSIVE MARKDOWN REPORT")
        print("="*80)
        
        # Generate current timestamp
        import datetime
        current_time = datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
        
        report_md = f"""# QCGE-SAS Study Report

## Measuring the Quality of Collaborative Group Engagement: AR Glasses + AI Assistance vs. No Assistance

---

### ğŸ“‹ ç ”ç©¶æ¦‚è¿°

**ç ”ç©¶é—®é¢˜ï¼š** ARçœ¼é•œç»“åˆAIè¾…åŠ©æ˜¯å¦èƒ½æå‡åä½œç»„å‚ä¸è´¨é‡ï¼Ÿ

**æ ·æœ¬é‡ï¼š** {len(self.data)} åå‚ä¸è€…

**ç ”ç©¶è®¾è®¡ï¼š** è¢«è¯•å†…æ¯”è¾ƒè®¾è®¡ (AR+AIè¾…åŠ© vs æ— è¾…åŠ©)

**æµ‹é‡å·¥å…·ï¼š** QCGE-SAS (åä½œç»„å‚ä¸è´¨é‡è‡ªæˆ‘è¯„ä¼°é‡è¡¨)

**å››ä¸ªç»´åº¦ï¼š** è¡Œä¸ºå‚ä¸(BE)ã€ç¤¾ä¼šå‚ä¸(SE)ã€è®¤çŸ¥å‚ä¸(CE)ã€æ¦‚å¿µåˆ°ç»“æœå‚ä¸(CC)

---

### ğŸ”¬ åˆ†ææ–¹æ³•

**æ­¥éª¤1ï¼š** ä¿¡åº¦åˆ†æ - è®¡ç®—å„ç»´åº¦Cronbach's Î±ç³»æ•°

**æ­¥éª¤2ï¼š** æè¿°ç»Ÿè®¡ä¸æ­£æ€æ€§æ£€éªŒ - Shapiro-Wilkæ£€éªŒ

**æ­¥éª¤3ï¼š** é…å¯¹æ¯”è¾ƒåˆ†æ - æ ¹æ®æ­£æ€æ€§é€‰æ‹©tæ£€éªŒæˆ–Wilcoxonæ£€éªŒ

**æ•ˆåº”é‡ï¼š** Cohen's d (å‚æ•°æ£€éªŒ) æˆ– r (éå‚æ•°æ£€éªŒ)

**æ˜¾è‘—æ€§æ°´å¹³ï¼š** Î± = 0.05

---

## ğŸ“Š åˆ†æç»“æœ

### 1. ä¿¡åº¦åˆ†æç»“æœ

**ä¿¡åº¦è§£é‡Šæ ‡å‡†ï¼š**
- Î± â‰¥ 0.9ï¼šä¼˜ç§€ (Excellent)
- 0.8 â‰¤ Î± < 0.9ï¼šè‰¯å¥½ (Good)
- 0.7 â‰¤ Î± < 0.8ï¼šå¯æ¥å— (Acceptable)
- 0.6 â‰¤ Î± < 0.7ï¼šå¯ç–‘ (Questionable)
- Î± < 0.6ï¼šå·® (Poor)

| Scale | Condition | Items | Cronbach's Î± | Total Score Mean | Total Score SD | Reliability Quality |
|-------|-----------|-------|--------------|------------------|----------------|-------------------|
"""
        
        # Add reliability results to table
        no_assistance_scales = ['BE_N', 'SE_N', 'CE_N', 'CC_N', 'Total_N']
        assistance_scales = ['BE_A', 'SE_A', 'CE_A', 'CC_A', 'Total_A']
        
        # No assistance condition
        for scale in no_assistance_scales:
            if scale in reliability_results:
                result = reliability_results[scale]
                if not np.isnan(result['alpha']):
                    report_md += f"| {scale} | No Assistance | {result['n_items']} | {result['alpha']:.3f} | {result['mean_total']:.1f} | {result['std_total']:.1f} | {result['interpretation']} |\n"
        
        # Assistance condition
        for scale in assistance_scales:
            if scale in reliability_results:
                result = reliability_results[scale]
                if not np.isnan(result['alpha']):
                    report_md += f"| {scale} | AR+AI Assistance | {result['n_items']} | {result['alpha']:.3f} | {result['mean_total']:.1f} | {result['std_total']:.1f} | {result['interpretation']} |\n"
        
        report_md += """

---

### 2. æè¿°ç»Ÿè®¡ä¸æ­£æ€æ€§æ£€éªŒç»“æœ

**æ­£æ€æ€§åˆ¤æ–­æ ‡å‡†ï¼š** Shapiro-Wilkæ£€éªŒ p â‰¥ 0.05 ä¸ºæ­£æ€åˆ†å¸ƒï¼Œp < 0.05 ä¸ºéæ­£æ€åˆ†å¸ƒ

| Dimension | Condition | Mean (M) | SD | Median | Min | Max | Range | Shapiro-Wilk p | Distribution |
|-----------|-----------|----------|----|--------|-----|-----|-------|----------------|--------------|
"""
        
        # Add descriptive results to table
        for dim, config in self.scale_structure.items():
            if dim in descriptive_results:
                n_data = descriptive_results[dim]['N']
                a_data = descriptive_results[dim]['A']
                
                report_md += f"""| {dim} | No Assistance | {n_data['mean']:.3f} | {n_data['sd']:.3f} | {n_data['median']:.3f} | {n_data['min']:.3f} | {n_data['max']:.3f} | {n_data['range']:.3f} | {n_data['shapiro_p']:.4f} | {n_data['dist_type']} |
| {dim} | AR+AI Assistance | {a_data['mean']:.3f} | {a_data['sd']:.3f} | {a_data['median']:.3f} | {a_data['min']:.3f} | {a_data['max']:.3f} | {a_data['range']:.3f} | {a_data['shapiro_p']:.4f} | {a_data['dist_type']} |
"""
        
        report_md += """

---

### 3. é…å¯¹æ¯”è¾ƒåˆ†æç»“æœ

**æ•ˆåº”é‡è§£é‡Šæ ‡å‡†ï¼š**
- **Cohen's dï¼š** |d| < 0.2 (å°æ•ˆåº”), 0.2 â‰¤ |d| < 0.5 (ä¸­ç­‰æ•ˆåº”), |d| â‰¥ 0.5 (å¤§æ•ˆåº”)
- **rï¼š** |r| < 0.1 (å°æ•ˆåº”), 0.1 â‰¤ |r| < 0.3 (ä¸­ç­‰æ•ˆåº”), |r| â‰¥ 0.3 (å¤§æ•ˆåº”)

| Dimension | Test Method | Statistic | p-value | Significance | Effect Size Type | Effect Size Value | Effect Size Interpretation | Mean Difference | N |
|-----------|-------------|-----------|---------|--------------|------------------|-------------------|---------------------------|-----------------|---|
"""
        
        # Add paired comparison results to table
        for dim, config in self.scale_structure.items():
            if dim in paired_results:
                result = paired_results[dim]
                report_md += f"| {dim} | {result['test_method']} | {result['test_stat']} | {result['p_value']:.4f} | {result['significance']} | {result['effect_size'].split('=')[0]} | {result['effect_size']} | {result['effect_interpretation']} | {result['mean_diff']:+.3f} | {result['n_pairs']} |\n"
        
        report_md += f"""

---

## ğŸ“ˆ å›¾è¡¨å±•ç¤º

### Figure 1: Reliability Comparison

![Reliability Comparison Chart](reliability_comparison.png)

*å„ç»´åº¦åœ¨ä¸¤ç§æ¡ä»¶ä¸‹çš„Cronbach's Î±ç³»æ•°å¯¹æ¯”ã€‚æ•°å€¼è¶Šé«˜è¡¨ç¤ºå†…éƒ¨ä¸€è‡´æ€§è¶Šå¥½ã€‚*

---

### Figure 2: Intervention Effect

![Intervention Effect Chart](intervention_effect.png)

*AR+AIè¾…åŠ©ç›¸å¯¹äºæ— è¾…åŠ©çš„æ”¹å–„æ•ˆæœã€‚æ­£å€¼è¡¨ç¤ºæ”¹å–„ï¼Œè´Ÿå€¼è¡¨ç¤ºä¸‹é™ã€‚é¢œè‰²è¡¨ç¤ºç»Ÿè®¡æ˜¾è‘—æ€§ã€‚*

---

### Figure 3: Effect Size Forest Plot

![Effect Size Forest Plot](effect_size_forest_plot.png)

*å„ç»´åº¦çš„æ ‡å‡†åŒ–æ•ˆåº”é‡ã€‚æ•ˆåº”é‡å¤§å°ç”¨é¢œè‰²åŒºåˆ†ï¼šè“è‰²(å°)ã€ç´«è‰²(ä¸­)ã€æ©™è‰²(å¤§)ã€‚*

---

## ğŸ’¡ ä¸»è¦å‘ç°

### ğŸ” å…³é”®ç»“æœæ€»ç»“

- **ä¿¡åº¦ï¼š** QCGE-SASåœ¨ä¸¤ç§æ¡ä»¶ä¸‹éƒ½è¡¨ç°å‡ºè‰¯å¥½çš„å†…éƒ¨ä¸€è‡´æ€§
- **å¹²é¢„æ•ˆæœï¼š** AR+AIè¾…åŠ©åœ¨å¤šä¸ªç»´åº¦ä¸Šæ˜¾ç¤ºå‡ºç§¯ææ”¹å–„
- **ç»Ÿè®¡æ˜¾è‘—æ€§ï¼š** éƒ¨åˆ†ç»´åº¦è¾¾åˆ°ç»Ÿè®¡æ˜¾è‘—æ°´å¹³
- **æ•ˆåº”é‡ï¼š** ä»å¾®å°åˆ°ä¸­ç­‰æ•ˆåº”ä¸ç­‰

---

## ğŸ“š ç ”ç©¶æ„ä¹‰

### ğŸ¯ å®è·µæ„ä¹‰

- AR+AIè¾…åŠ©æŠ€æœ¯å¯ä»¥æå‡åä½œç»„å‚ä¸è´¨é‡
- ä¸ºæ•™è‚²å’ŒæŠ€æœ¯åº”ç”¨æä¾›å®è¯æ”¯æŒ
- æŒ‡å¯¼åä½œå­¦ä¹ ç¯å¢ƒçš„è®¾è®¡å’Œä¼˜åŒ–

### ğŸ”¬ ç†è®ºæ„ä¹‰

- æ”¯æŒæŠ€æœ¯å¢å¼ºå­¦ä¹ å’Œåä½œç†è®º
- éªŒè¯QCGE-SASé‡è¡¨çš„æœ‰æ•ˆæ€§
- ä¸ºåç»­ç ”ç©¶æä¾›æ–¹æ³•è®ºåŸºç¡€

---

## ğŸ“‹ æŠ¥å‘Šä¿¡æ¯

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š** {current_time}

**æ•°æ®æ¥æºï¼š** QCGE-SAS Study Data

**åˆ†æå·¥å…·ï¼š** Python QCGE-SAS Analyzer

**ç ”ç©¶ï¼š** AR Glasses + AI Assistance vs. No Assistance in Collaborative Tasks

---

*æœ¬æŠ¥å‘Šç”±Python QCGE-SASåˆ†æå™¨è‡ªåŠ¨ç”Ÿæˆï¼ŒåŒ…å«å®Œæ•´çš„ç»Ÿè®¡åˆ†æç»“æœå’Œå¯è§†åŒ–å›¾è¡¨ã€‚*
"""
        
        # Save Markdown report
        with open('qcge_sas_study_report.md', 'w', encoding='utf-8') as f:
            f.write(report_md)
        
        print("âœ… MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: qcge_sas_study_report.md")
        print("ğŸ’¡ æç¤ºï¼šå¯ä»¥ç”¨Markdownç¼–è¾‘å™¨æŸ¥çœ‹ï¼Œæˆ–è½¬æ¢ä¸ºå…¶ä»–æ ¼å¼")
        
        return report_md

    def generate_comprehensive_report(self):
        """Generate complete analysis report"""
        print("\nğŸš€ Starting QCGE-SAS comprehensive analysis...")
        print("Study: AR Glasses + AI Assistance vs. No Assistance")
        print("Scale: Quality of Collaborative Group Engagement (QCGE-SAS)")
        print("="*80)
        
        # Step 1: Reliability Analysis
        print("\nğŸ“Š STEP 1: RELIABILITY ANALYSIS")
        reliability_results = self.analyze_reliability()
        
        # Step 2: Descriptive Statistics & Normality Test
        print("\nğŸ“Š STEP 2: DESCRIPTIVE STATISTICS & NORMALITY TEST")
        descriptive_results = self.analyze_descriptive_and_normality()
        
        # Step 3: Paired Comparison Analysis
        print("\nğŸ“Š STEP 3: PAIRED COMPARISON ANALYSIS")
        paired_results = self.analyze_paired_comparison(descriptive_results)
        
        # Step 4: Create publication charts
        print("\nğŸ“Š STEP 4: CREATING PUBLICATION CHARTS")
        self.create_publication_charts(reliability_results, descriptive_results, paired_results)
        
        # Step 5: Generate HTML report
        print("\nğŸ“Š STEP 5: GENERATING HTML REPORT")
        self.generate_html_report(reliability_results, descriptive_results, paired_results)
        
        # Step 6: Generate Markdown report
        print("\nğŸ“Š STEP 6: GENERATING MARKDOWN REPORT")
        self.generate_markdown_report(reliability_results, descriptive_results, paired_results)
        
        # Final summary
        print("\n" + "="*80)
        print("ğŸ“‹ COMPREHENSIVE ANALYSIS COMPLETE")
        print("="*80)
        print("âœ… All analyses completed!")
        print("ğŸ“Š Three core tables generated")
        print("ğŸ“ˆ Three publication-quality charts created and saved")
        print("ğŸ“„ HTML report generated for publication")
        print("\nğŸ“ Files created:")
        print("   â€¢ reliability_comparison.png")
        print("   â€¢ intervention_effect.png")
        print("   â€¢ effect_size_forest_plot.png")
        print("   â€¢ qcge_sas_study_report.html")
        print("   â€¢ qcge_sas_study_report.md")
        print("\nğŸ’¡ HTMLæŠ¥å‘Šä½¿ç”¨è¯´æ˜:")
        print("   1. ç”¨æµè§ˆå™¨æ‰“å¼€ qcge_sas_study_report.html")
        print("   2. æŒ‰Ctrl+P (æˆ–Cmd+P) æ‰“å¼€æ‰“å°å¯¹è¯æ¡†")
        print("   3. é€‰æ‹©'ä¿å­˜ä¸ºPDF'å³å¯è·å¾—PDFç‰ˆæœ¬")
        print("\nğŸ’¡ MarkdownæŠ¥å‘Šä½¿ç”¨è¯´æ˜:")
        print("   1. ç”¨Markdownç¼–è¾‘å™¨æ‰“å¼€ qcge_sas_study_report.md")
        print("   2. å¯ä»¥è½¬æ¢ä¸ºå…¶ä»–æ ¼å¼ï¼ˆå¦‚PDFã€HTMLã€DOCXç­‰ï¼‰")
        
        return {
            'reliability': reliability_results,
            'descriptive': descriptive_results,
            'paired': paired_results
        }

def main():
    """Main function"""
    print("ğŸ” QCGE-SAS Study Analyzer")
    print("="*60)
    print("Study: AR Glasses + AI Assistance vs. No Assistance")
    print("Scale: Quality of Collaborative Group Engagement (QCGE-SAS)")
    print("="*60)
    
    try:
        analyzer = QCGESASAnalyzer('Scale_data.csv')
        results = analyzer.generate_comprehensive_report()
        
    except FileNotFoundError:
        print("âŒ Error: File 'Scale_data.csv' not found!")
        print("Please ensure the data file is in the current directory.")
    except Exception as e:
        print(f"âŒ Error occurred: {e}")
        print("Please check your data file and try again.")

if __name__ == "__main__":
    main()
