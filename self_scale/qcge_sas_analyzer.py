#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
QCGE-SAS Study Analyzer
Study: AR glasses + AI assistance vs. No assistance
Scale: Quality of Collaborative Group Engagement
Author: AI Assistant
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import shapiro, ttest_rel, wilcoxon
import warnings
warnings.filterwarnings('ignore')

# Set academic journal style
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['font.size'] = 12
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['axes.titlesize'] = 16
plt.rcParams['xtick.labelsize'] = 12
plt.rcParams['ytick.labelsize'] = 12
plt.rcParams['legend.fontsize'] = 12
plt.rcParams['figure.titlesize'] = 18

class QCGESASAnalyzer:
    def __init__(self, csv_file_path):
        """Initialize the analyzer with QCGE-SAS data"""
        self.data = pd.read_csv(csv_file_path)
        print(f"‚úÖ QCGE-SAS Data loaded successfully!")
        print(f"   Study: AR glasses + AI assistance vs. No assistance")
        print(f"   Total participants: {len(self.data)}")
        
        # Define scale structure for QCGE-SAS
        self.scale_structure = {
            'BE': {'N': 'BE_N_mean', 'A': 'BE_A_mean', 'description': 'Behavioral Engagement'},
            'SE': {'N': 'SE_N_mean', 'A': 'SE_A_mean', 'description': 'Social Engagement'},
            'CE': {'N': 'CE_N_mean', 'A': 'CE_A_mean', 'description': 'Cognitive Engagement'},
            'CC': {'N': 'CC_N_mean', 'A': 'CC_A_mean', 'description': 'Conceptual-to-Consequential Engagement'},
            'Total': {'N': 'Total_N', 'A': 'Total_A', 'description': 'Total Scale'}
        }
        
        # Define reliability structure
        self.reliability_structure = {
            'BE_N': {'variables': ['BE1_N', 'BE2_N', 'BE4_N'], 'description': 'BE (No assistance)'},
            'SE_N': {'variables': ['SE1_N', 'SE2R_N', 'SE4R_N', 'SE6R_N'], 'description': 'SE (No assistance)'},
            'CE_N': {'variables': ['CE1_N', 'CE2_N', 'CE3_N'], 'description': 'CE (No assistance)'},
            'CC_N': {'variables': ['CC3_N', 'CC5_N', 'CC7_N'], 'description': 'CC (No assistance)'},
            'Total_N': {'variables': ['BE1_N', 'BE2_N', 'BE4_N', 'SE1_N', 'SE2R_N', 'SE4R_N', 'SE6R_N', 'CE1_N', 'CE2_N', 'CE3_N', 'CC3_N', 'CC5_N', 'CC7_N'], 'description': 'Total (No assistance)'},
            'BE_A': {'variables': ['BE1_A', 'BE2_A', 'BE4_A'], 'description': 'BE (AR+AI assistance)'},
            'SE_A': {'variables': ['SE1_A', 'SE2R_A', 'SE4R_A', 'SE6R_A'], 'description': 'SE (AR+AI assistance)'},
            'CE_A': {'variables': ['CE1_A', 'CE2_A', 'CE3_A'], 'description': 'CE (AR+AI assistance)'},
            'CC_A': {'variables': ['CC3_A', 'CC5_A', 'CC7_A'], 'description': 'CC (AR+AI assistance)'},
            'Total_A': {'variables': ['BE1_A', 'BE2_A', 'BE4_A', 'SE1_A', 'SE2R_A', 'SE4R_A', 'SE6R_A', 'CE1_A', 'CE2_A', 'CE3_A', 'CC3_A', 'CC5_A', 'CC7_A'], 'description': 'Total (AR+AI assistance)'}
        }
    
    def calculate_cronbach_alpha(self, variables):
        """Calculate Cronbach's Œ±"""
        if len(variables) < 2:
            return np.nan, np.nan, np.nan
            
        item_data = self.data[variables].dropna()
        if len(item_data) == 0:
            return np.nan, np.nan, np.nan
            
        item_variances = item_data.var()
        total_variance = item_data.sum(axis=1).var()
        
        n_items = len(variables)
        if total_variance == 0:
            return np.nan, np.nan, np.nan
            
        alpha = (n_items / (n_items - 1)) * (1 - item_variances.sum() / total_variance)
        total_scores = item_data.sum(axis=1)
        mean_total = total_scores.mean()
        std_total = total_scores.std()
        
        return alpha, mean_total, std_total
    
    def analyze_reliability(self):
        """Step 1: Reliability Analysis"""
        print("\n" + "="*80)
        print("üìä TABLE 1: RELIABILITY ANALYSIS - Cronbach's Œ±")
        print("="*80)
        
        results = {}
        
        for scale_name, scale_info in self.reliability_structure.items():
            print(f"\nüîç {scale_info['description']}")
            print("-" * 60)
            
            missing_vars = [var for var in scale_info['variables'] if var not in self.data.columns]
            if missing_vars:
                print(f"‚ùå Missing variables: {missing_vars}")
                continue
            
            alpha, mean_total, std_total = self.calculate_cronbach_alpha(scale_info['variables'])
            
            if not np.isnan(alpha):
                print(f"  Variables: {', '.join(scale_info['variables'])}")
                print(f"  Number of items: {len(scale_info['variables'])}")
                print(f"  Cronbach's Œ±: {alpha:.4f}")
                print(f"  Total score - Mean: {mean_total:.3f}")
                print(f"  Total score - Std: {std_total:.3f}")
                
                if alpha >= 0.9:
                    interpretation = "Excellent"
                elif alpha >= 0.8:
                    interpretation = "Good"
                elif alpha >= 0.7:
                    interpretation = "Acceptable"
                elif alpha >= 0.6:
                    interpretation = "Questionable"
                else:
                    interpretation = "Poor"
                print(f"  Reliability: {interpretation}")
                
                results[scale_name] = {
                    'alpha': alpha, 'n_items': len(scale_info['variables']),
                    'mean_total': mean_total, 'std_total': std_total,
                    'interpretation': interpretation, 'variables': scale_info['variables']
                }
            else:
                print(f"  ‚ùå Cannot calculate Œ± for {scale_name}")
                results[scale_name] = {
                    'alpha': np.nan, 'n_items': len(scale_info['variables']),
                    'mean_total': np.nan, 'std_total': np.nan,
                    'interpretation': 'N/A', 'variables': scale_info['variables']
                }
        
        self.create_reliability_table(results)
        return results
    
    def create_reliability_table(self, results):
        """Create reliability summary table"""
        print("\n" + "="*80)
        print("üìã RELIABILITY SUMMARY TABLE")
        print("="*80)
        
        print(f"{'Scale':<12} {'Condition':<20} {'Items':<6} {'Œ±':<8} {'Mean':<8} {'Std':<8} {'Quality':<12}")
        print("-" * 80)
        
        no_assistance_scales = ['BE_N', 'SE_N', 'CE_N', 'CC_N', 'Total_N']
        assistance_scales = ['BE_A', 'SE_A', 'CE_A', 'CC_A', 'Total_A']
        
        print("  üìä NO ASSISTANCE CONDITION")
        print("-" * 80)
        for scale in no_assistance_scales:
            if scale in results:
                result = results[scale]
                if not np.isnan(result['alpha']):
                    print(f"{scale:<12} {'No assistance':<20} {result['n_items']:<6} {result['alpha']:<8.3f} {result['mean_total']:<8.1f} {result['std_total']:<8.1f} {result['interpretation']:<12}")
        
        print()
        print("  üìä AR+AI ASSISTANCE CONDITION")
        print("-" * 80)
        for scale in assistance_scales:
            if scale in results:
                result = results[scale]
                if not np.isnan(result['alpha']):
                    print(f"{scale:<12} {'AR+AI assistance':<20} {result['n_items']:<6} {result['alpha']:<8.3f} {result['mean_total']:<8.1f} {result['std_total']:<8.1f} {result['interpretation']:<12}")
        
        print("-" * 80)
    
    def analyze_descriptive_and_normality(self):
        """Step 2: Descriptive Statistics + Normality Test"""
        print("\n" + "="*80)
        print("üìä TABLE 2: DESCRIPTIVE STATISTICS & NORMALITY TEST")
        print("="*80)
        
        results = {}
        
        for dim, config in self.scale_structure.items():
            print(f"\nüîç {config['description']} ({dim})")
            print("-" * 50)
            
            if config['N'] not in self.data.columns or config['A'] not in self.data.columns:
                print(f"‚ùå Missing variables for {dim}")
                continue
            
            n_data = self.data[config['N']].dropna()
            a_data = self.data[config['A']].dropna()
            
            if len(n_data) == 0 or len(a_data) == 0:
                print(f"‚ùå No data available for {dim}")
                continue
            
            # Calculate descriptive statistics
            n_mean, n_sd = n_data.mean(), n_data.std()
            n_median, n_min, n_max = n_data.median(), n_data.min(), n_data.max()
            n_range = n_max - n_min
            
            a_mean, a_sd = a_data.mean(), a_data.std()
            a_median, a_min, a_max = a_data.median(), a_data.min(), a_data.max()
            a_range = a_max - a_min
            
            # Shapiro-Wilk normality test
            n_shapiro_p = shapiro(n_data)[1]
            a_shapiro_p = shapiro(a_data)[1]
            
            n_dist_type = "Normal" if n_shapiro_p >= 0.05 else "Non-normal"
            a_dist_type = "Normal" if a_shapiro_p >= 0.05 else "Non-normal"
            
            results[dim] = {
                'N': {'mean': n_mean, 'sd': n_sd, 'median': n_median, 'min': n_min, 'max': n_max, 'range': n_range, 'shapiro_p': n_shapiro_p, 'dist_type': n_dist_type},
                'A': {'mean': a_mean, 'sd': a_sd, 'median': a_median, 'min': a_min, 'max': a_max, 'range': a_range, 'shapiro_p': a_shapiro_p, 'dist_type': a_dist_type}
            }
            
            print(f"  No assistance (N): M={n_mean:.3f}, SD={n_sd:.3f}, Range: {n_min:.3f}-{n_max:.3f}, p={n_shapiro_p:.4f} ‚Üí {n_dist_type}")
            print(f"  AR+AI assistance (A): M={a_mean:.3f}, SD={a_sd:.3f}, Range: {a_min:.3f}-{a_max:.3f}, p={a_shapiro_p:.4f} ‚Üí {a_dist_type}")
        
        self.create_descriptive_table(results)
        return results
    
    def create_descriptive_table(self, results):
        """Create descriptive statistics table"""
        print("\n" + "="*100)
        print("üìã DESCRIPTIVE STATISTICS & NORMALITY TEST TABLE")
        print("="*100)
        
        print(f"{'Dimension':<10} {'Condition':<20} {'M':<8} {'SD':<8} {'Median':<8} {'Min':<8} {'Max':<8} {'Range':<8} {'Shapiro-Wilk p':<15} {'Distribution':<12}")
        print("-" * 100)
        
        for dim, config in self.scale_structure.items():
            if dim in results:
                n_data = results[dim]['N']
                a_data = results[dim]['A']
                
                print(f"{dim:<10} {'No assistance':<20} {n_data['mean']:<8.3f} {n_data['sd']:<8.3f} {n_data['median']:<8.3f} {n_data['min']:<8.3f} {n_data['max']:<8.3f} {n_data['range']:<8.3f} {n_data['shapiro_p']:<15.4f} {n_data['dist_type']:<12}")
                print(f"{dim:<10} {'AR+AI assistance':<20} {a_data['mean']:<8.3f} {a_data['sd']:<8.3f} {a_data['median']:<8.3f} {a_data['min']:<8.3f} {a_data['max']:<8.3f} {a_data['range']:<8.3f} {a_data['shapiro_p']:<15.4f} {a_data['dist_type']:<12}")
        
        print("-" * 100)
    
    def analyze_paired_comparison(self, descriptive_results):
        """Step 3: Paired Comparison Analysis"""
        print("\n" + "="*80)
        print("üìä TABLE 3: PAIRED COMPARISON ANALYSIS")
        print("="*80)
        
        results = {}
        
        for dim, config in self.scale_structure.items():
            print(f"\nüîç {config['description']} ({dim})")
            print("-" * 50)
            
            if dim not in descriptive_results:
                print(f"‚ùå No descriptive results for {dim}")
                continue
            
            n_data = self.data[config['N']].dropna()
            a_data = self.data[config['A']].dropna()
            
            common_indices = n_data.index.intersection(a_data.index)
            if len(common_indices) < 2:
                print(f"‚ùå Insufficient paired data for {dim}")
                continue
            
            n_paired = n_data.loc[common_indices]
            a_paired = a_data.loc[common_indices]
            
            # Determine test method
            n_normal = descriptive_results[dim]['N']['dist_type'] == "Normal"
            a_normal = descriptive_results[dim]['A']['dist_type'] == "Normal"
            
            if n_normal and a_normal:
                test_method = "Paired t-test"
                stat, p_value = ttest_rel(n_paired, a_paired)
                test_stat = f"t={stat:.3f}"
                
                # Cohen's d
                mean_diff = (a_paired - n_paired).mean()
                pooled_sd = np.sqrt(((n_paired.var() + a_paired.var()) / 2))
                cohens_d = mean_diff / pooled_sd if pooled_sd > 0 else 0
                effect_size = f"d={cohens_d:.3f}"
                
                if abs(cohens_d) < 0.2:
                    effect_interpretation = "Small"
                elif abs(cohens_d) < 0.5:
                    effect_interpretation = "Medium"
                elif abs(cohens_d) < 0.8:
                    effect_interpretation = "Large"
                else:
                    effect_interpretation = "Very large"
                
            else:
                test_method = "Wilcoxon test"
                stat, p_value = wilcoxon(n_paired, a_paired)
                test_stat = f"W={stat:.3f}"
                
                # r effect size
                n = len(common_indices)
                r = abs(stat) / (n * (n + 1) / 2)
                effect_size = f"r={r:.3f}"
                
                if r < 0.1:
                    effect_interpretation = "Small"
                elif r < 0.3:
                    effect_interpretation = "Medium"
                elif r < 0.5:
                    effect_interpretation = "Large"
                else:
                    effect_interpretation = "Very large"
            
            mean_diff = (a_paired - n_paired).mean()
            significance = "p < 0.05" if p_value < 0.05 else "p ‚â• 0.05"
            
            results[dim] = {
                'test_method': test_method, 'test_stat': test_stat, 'p_value': p_value,
                'significance': significance, 'effect_size': effect_size,
                'effect_interpretation': effect_interpretation, 'mean_diff': mean_diff,
                'n_pairs': len(common_indices)
            }
            
            print(f"  Test method: {test_method}")
            print(f"  Test statistic: {test_stat}")
            print(f"  p-value: {p_value:.4f}")
            print(f"  Significance: {significance}")
            print(f"  Effect size: {effect_size} ({effect_interpretation})")
            print(f"  Mean difference (AR+AI - No assistance): {mean_diff:.3f}")
            print(f"  Paired samples: {len(common_indices)}")
        
        self.create_paired_comparison_table(results)
        return results
    
    def create_paired_comparison_table(self, results):
        """Create paired comparison table"""
        print("\n" + "="*100)
        print("üìã PAIRED COMPARISON ANALYSIS TABLE")
        print("="*100)
        
        print(f"{'Dimension':<10} {'Test Method':<15} {'Statistic':<12} {'p-value':<10} {'Significance':<12} {'Effect Size':<12} {'Effect Size Value':<15} {'Interpretation':<12} {'Mean Diff':<12} {'N':<6}")
        print("-" * 100)
        
        for dim, config in self.scale_structure.items():
            if dim in results:
                result = results[dim]
                print(f"{dim:<10} {result['test_method']:<15} {result['test_stat']:<12} {result['p_value']:<10.4f} {result['significance']:<12} {result['effect_size'].split('=')[0]:<12} {result['effect_size']:<15} {result['effect_interpretation']:<12} {result['mean_diff']:<+12.3f} {result['n_pairs']:<6}")
        
        print("-" * 100)
    
    def create_publication_charts(self, reliability_results, descriptive_results, paired_results):
        """Create publication-quality charts"""
        print("\n" + "="*80)
        print("üìä CREATING PUBLICATION-QUALITY CHARTS")
        print("="*80)
        
        # 1. Reliability Comparison Chart
        self.create_reliability_chart(reliability_results)
        
        # 2. Intervention Effect Chart
        self.create_intervention_effect_chart(paired_results)
        
        # 3. Effect Size Forest Plot
        self.create_effect_size_forest_plot(paired_results)
        
        print("‚úÖ All publication charts created and saved!")
    
    def create_reliability_chart(self, results):
        """Create reliability comparison chart"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        dimensions = ['BE', 'SE', 'CE', 'CC', 'Total']
        no_assist_alphas = []
        assist_alphas = []
        
        for dim in dimensions:
            n_scale = f"{dim}_N"
            a_scale = f"{dim}_A"
            
            if n_scale in results and a_scale in results:
                no_assist_alphas.append(results[n_scale]['alpha'])
                assist_alphas.append(results[a_scale]['alpha'])
            else:
                no_assist_alphas.append(np.nan)
                assist_alphas.append(np.nan)
        
        x = np.arange(len(dimensions))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, no_assist_alphas, width, label='No assistance', 
                       color='#2E86AB', alpha=0.8, edgecolor='#1B4965')
        bars2 = ax.bar(x + width/2, assist_alphas, width, label='AR+AI assistance', 
                       color='#A23B72', alpha=0.8, edgecolor='#8B2E5C')
        
        ax.set_xlabel('Scale Dimensions')
        ax.set_ylabel("Cronbach's Œ±")
        ax.set_title('Reliability Comparison: No Assistance vs AR+AI Assistance')
        ax.set_xticks(x)
        ax.set_xticklabels(dimensions)
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)
        
        # Add value labels
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                if not np.isnan(height):
                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                           f'{height:.3f}', ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        plt.savefig('reliability_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_intervention_effect_chart(self, results):
        """Create intervention effect chart"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        dimensions = ['BE', 'SE', 'CE', 'CC', 'Total']
        mean_diffs = []
        effect_sizes = []
        colors = []
        
        for dim in dimensions:
            if dim in results:
                result = results[dim]
                mean_diffs.append(result['mean_diff'])
                
                if 'd=' in result['effect_size']:
                    effect_size_val = float(result['effect_size'].split('=')[1])
                else:
                    effect_size_val = float(result['effect_size'].split('=')[1])
                
                effect_sizes.append(effect_size_val)
                
                if result['p_value'] < 0.05:
                    colors.append('#A23B72')  # Significant
                else:
                    colors.append('#2E86AB')  # Not significant
        
        bars = ax.bar(dimensions, mean_diffs, color=colors, alpha=0.8, edgecolor='black')
        
        # Add effect size labels
        for i, (bar, effect_size) in enumerate(zip(bars, effect_sizes)):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + (0.01 if height > 0 else -0.01),
                   f'd={effect_size:.2f}', ha='center', va='bottom' if height > 0 else 'top', fontsize=10)
        
        ax.set_xlabel('Scale Dimensions')
        ax.set_ylabel('Mean Difference (AR+AI - No assistance)')
        ax.set_title('Intervention Effect: AR+AI Assistance vs No Assistance')
        ax.axhline(y=0, color='black', linestyle='-', alpha=0.5)
        ax.grid(True, alpha=0.3)
        
        from matplotlib.patches import Patch
        legend_elements = [Patch(facecolor='#A23B72', label='Significant (p < 0.05)'),
                          Patch(facecolor='#2E86AB', label='Not significant (p ‚â• 0.05)')]
        ax.legend(handles=legend_elements)
        
        plt.tight_layout()
        plt.savefig('intervention_effect.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_effect_size_forest_plot(self, results):
        """Create effect size forest plot"""
        fig, ax = plt.subplots(figsize=(10, 8))
        
        dimensions = ['BE', 'SE', 'CE', 'CC', 'Total']
        effect_sizes = []
        effect_size_types = []
        
        for dim in dimensions:
            if dim in results:
                result = results[dim]
                
                if 'd=' in result['effect_size']:
                    effect_size_val = float(result['effect_size'].split('=')[1])
                    effect_size_types.append('Cohen\'s d')
                else:
                    effect_size_val = float(result['effect_size'].split('=')[1])
                    effect_size_types.append('r')
                
                effect_sizes.append(effect_size_val)
        
        y_pos = np.arange(len(dimensions))
        
        # Color based on effect size magnitude
        colors = []
        for effect_size in effect_sizes:
            if abs(effect_size) < 0.2:
                colors.append('#2E86AB')  # Small
            elif abs(effect_size) < 0.5:
                colors.append('#A23B72')  # Medium
            else:
                colors.append('#F18F01')  # Large
        
        bars = ax.barh(y_pos, effect_sizes, color=colors, alpha=0.8, edgecolor='black')
        
        # Add effect size labels
        for i, (bar, effect_size, effect_type) in enumerate(zip(bars, effect_sizes, effect_size_types)):
            width = bar.get_width()
            ax.text(width + (0.01 if width > 0 else -0.01), bar.get_y() + bar.get_height()/2.,
                   f'{effect_type}={effect_size:.2f}', ha='left' if width > 0 else 'right', va='center', fontsize=10)
        
        ax.set_yticks(y_pos)
        ax.set_yticklabels(dimensions)
        ax.set_xlabel('Effect Size')
        ax.set_title('Effect Sizes by Dimension')
        ax.axvline(x=0, color='black', linestyle='-', alpha=0.5)
        ax.grid(True, alpha=0.3)
        
        from matplotlib.patches import Patch
        legend_elements = [Patch(facecolor='#2E86AB', label='Small effect (< 0.2)'),
                          Patch(facecolor='#A23B72', label='Medium effect (0.2-0.5)'),
                          Patch(facecolor='#F18F01', label='Large effect (> 0.5)')]
        ax.legend(handles=legend_elements)
        
        plt.tight_layout()
        plt.savefig('effect_size_forest_plot.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_html_report(self, reliability_results, descriptive_results, paired_results):
        """Generate comprehensive HTML report with all results and charts"""
        print("\n" + "="*80)
        print("üìÑ GENERATING COMPREHENSIVE HTML REPORT")
        print("="*80)
        
        # Generate current timestamp
        import datetime
        current_time = datetime.datetime.now().strftime('%YÂπ¥%mÊúà%dÊó• %H:%M:%S')
        
        report_html = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>QCGE-SAS Study Report</title>
            <style>
                body {{
                    font-family: 'Microsoft YaHei', 'SimSun', serif;
                    line-height: 1.6;
                    margin: 0;
                    padding: 20px;
                    background-color: #f5f5f5;
                    color: #333;
                }}
                .container {{
                    max-width: 1200px;
                    margin: 0 auto;
                    background-color: white;
                    padding: 30px;
                    border-radius: 10px;
                    box-shadow: 0 0 20px rgba(0,0,0,0.1);
                }}
                h1 {{
                    color: #2c3e50;
                    text-align: center;
                    border-bottom: 3px solid #3498db;
                    padding-bottom: 20px;
                    margin-bottom: 30px;
                    font-size: 28px;
                }}
                h2 {{
                    color: #34495e;
                    margin-top: 40px;
                    margin-bottom: 20px;
                    border-left: 5px solid #3498db;
                    padding-left: 20px;
                    font-size: 24px;
                }}
                h3 {{
                    color: #7f8c8d;
                    margin-top: 30px;
                    margin-bottom: 15px;
                    font-size: 20px;
                }}
                .study-info {{
                    background-color: #e8f4f8;
                    padding: 20px;
                    border-radius: 8px;
                    margin: 20px 0;
                    border-left: 5px solid #3498db;
                }}
                .highlight {{
                    background-color: #fff3cd;
                    padding: 15px;
                    border-radius: 5px;
                    margin: 15px 0;
                    border-left: 5px solid #ffc107;
                }}
                .stats-box {{
                    background-color: #f8f9fa;
                    padding: 15px;
                    border-radius: 5px;
                    margin: 10px 0;
                    border: 1px solid #dee2e6;
                }}
                .chart-section {{
                    text-align: center;
                    margin: 30px 0;
                    padding: 20px;
                    background-color: #f8f9fa;
                    border-radius: 8px;
                }}
                .chart-section img {{
                    max-width: 80%;
                    width: auto;
                    height: auto;
                    max-height: 500px;
                    border: 2px solid #dee2e6;
                    border-radius: 5px;
                    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
                    object-fit: contain;
                }}
                @media (max-width: 768px) {{
                    .chart-section img {{
                        max-width: 95%;
                        max-height: 400px;
                    }}
                }}
                @media (max-width: 480px) {{
                    .chart-section img {{
                        max-width: 100%;
                        max-height: 300px;
                    }}
                }}
                .chart-caption {{
                    margin-top: 15px;
                    font-style: italic;
                    color: #666;
                    font-size: 14px;
                }}
                table {{
                    width: 100%;
                    border-collapse: collapse;
                    margin: 20px 0;
                    font-size: 14px;
                }}
                th, td {{
                    border: 1px solid #ddd;
                    padding: 12px;
                    text-align: center;
                    vertical-align: middle;
                }}
                th {{
                    background-color: #3498db;
                    color: white;
                    font-weight: bold;
                }}
                tr:nth-child(even) {{
                    background-color: #f2f2f2;
                }}
                tr:hover {{
                    background-color: #e8f4f8;
                }}
                .condition-header {{
                    background-color: #2c3e50 !important;
                    color: white !important;
                    font-weight: bold;
                }}
                .significant {{
                    color: #27ae60;
                    font-weight: bold;
                }}
                .not-significant {{
                    color: #e74c3c;
                }}
                .footer {{
                    margin-top: 40px;
                    padding: 20px;
                    background-color: #ecf0f1;
                    border-radius: 8px;
                    text-align: center;
                    color: #7f8c8d;
                }}
                .methodology {{
                    background-color: #e8f5e8;
                    padding: 20px;
                    border-radius: 8px;
                    margin: 20px 0;
                    border-left: 5px solid #27ae60;
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>QCGE-SAS Study Report</h1>
                <h2>Measuring the Quality of Collaborative Group Engagement: AR Glasses + AI Assistance vs. No Assistance</h2>
                
                <div class="study-info">
                    <h3>üìã Á†îÁ©∂Ê¶ÇËø∞</h3>
                    <p><strong>Á†îÁ©∂ÈóÆÈ¢òÔºö</strong>ARÁúºÈïúÁªìÂêàAIËæÖÂä©ÊòØÂê¶ËÉΩÊèêÂçáÂçè‰ΩúÁªÑÂèÇ‰∏éË¥®ÈáèÔºü</p>
                    <p><strong>Ê†∑Êú¨ÈáèÔºö</strong>{len(self.data)} ÂêçÂèÇ‰∏éËÄÖ</p>
                    <p><strong>Á†îÁ©∂ËÆæËÆ°Ôºö</strong>Ë¢´ËØïÂÜÖÊØîËæÉËÆæËÆ° (AR+AIËæÖÂä© vs Êó†ËæÖÂä©)</p>
                    <p><strong>ÊµãÈáèÂ∑•ÂÖ∑Ôºö</strong>QCGE-SAS (Âçè‰ΩúÁªÑÂèÇ‰∏éË¥®ÈáèËá™ÊàëËØÑ‰º∞ÈáèË°®)</p>
                    <p><strong>Âõõ‰∏™Áª¥Â∫¶Ôºö</strong>Ë°å‰∏∫ÂèÇ‰∏é(BE)„ÄÅÁ§æ‰ºöÂèÇ‰∏é(SE)„ÄÅËÆ§Áü•ÂèÇ‰∏é(CE)„ÄÅÊ¶ÇÂøµÂà∞ÁªìÊûúÂèÇ‰∏é(CC)</p>
                </div>
                
                <div class="methodology">
                    <h3>üî¨ ÂàÜÊûêÊñπÊ≥ï</h3>
                    <p><strong>Ê≠•È™§1Ôºö</strong>‰ø°Â∫¶ÂàÜÊûê - ËÆ°ÁÆóÂêÑÁª¥Â∫¶Cronbach's Œ±Á≥ªÊï∞</p>
                    <p><strong>Ê≠•È™§2Ôºö</strong>ÊèèËø∞ÁªüËÆ°‰∏éÊ≠£ÊÄÅÊÄßÊ£ÄÈ™å - Shapiro-WilkÊ£ÄÈ™å</p>
                    <p><strong>Ê≠•È™§3Ôºö</strong>ÈÖçÂØπÊØîËæÉÂàÜÊûê - Ê†πÊçÆÊ≠£ÊÄÅÊÄßÈÄâÊã©tÊ£ÄÈ™åÊàñWilcoxonÊ£ÄÈ™å</p>
                    <p><strong>ÊïàÂ∫îÈáèÔºö</strong>Cohen's d (ÂèÇÊï∞Ê£ÄÈ™å) Êàñ r (ÈùûÂèÇÊï∞Ê£ÄÈ™å)</p>
                    <p><strong>ÊòæËëóÊÄßÊ∞¥Âπ≥Ôºö</strong>Œ± = 0.05</p>
                </div>
                
                <h2>üìä ÂàÜÊûêÁªìÊûú</h2>
                
                <h3>1. ‰ø°Â∫¶ÂàÜÊûêÁªìÊûú</h3>
                <div class="stats-box">
                    <p><strong>‰ø°Â∫¶Ëß£ÈáäÊ†áÂáÜÔºö</strong></p>
                    <ul>
                        <li>Œ± ‚â• 0.9Ôºö‰ºòÁßÄ (Excellent)</li>
                        <li>0.8 ‚â§ Œ± < 0.9ÔºöËâØÂ•Ω (Good)</li>
                        <li>0.7 ‚â§ Œ± < 0.8ÔºöÂèØÊé•Âèó (Acceptable)</li>
                        <li>0.6 ‚â§ Œ± < 0.7ÔºöÂèØÁñë (Questionable)</li>
                        <li>Œ± < 0.6ÔºöÂ∑Æ (Poor)</li>
                    </ul>
                </div>
                
                <table>
                    <thead>
                        <tr>
                            <th>Scale</th>
                            <th>Condition</th>
                            <th>Items</th>
                            <th>Cronbach's Œ±</th>
                            <th>Total Score Mean</th>
                            <th>Total Score SD</th>
                            <th>Reliability Quality</th>
                        </tr>
                    </thead>
                    <tbody>
        """
        
        # Add reliability results to table
        no_assistance_scales = ['BE_N', 'SE_N', 'CE_N', 'CC_N', 'Total_N']
        assistance_scales = ['BE_A', 'SE_A', 'CE_A', 'CC_A', 'Total_A']
        
        # No assistance condition
        for scale in no_assistance_scales:
            if scale in reliability_results:
                result = reliability_results[scale]
                if not np.isnan(result['alpha']):
                    report_html += f"""
                        <tr>
                            <td>{scale}</td>
                            <td class="condition-header">No Assistance</td>
                            <td>{result['n_items']}</td>
                            <td>{result['alpha']:.3f}</td>
                            <td>{result['mean_total']:.1f}</td>
                            <td>{result['std_total']:.1f}</td>
                            <td>{result['interpretation']}</td>
                        </tr>
                    """
        
        # Assistance condition
        for scale in assistance_scales:
            if scale in reliability_results:
                result = reliability_results[scale]
                if not np.isnan(result['alpha']):
                    report_html += f"""
                        <tr>
                            <td>{scale}</td>
                            <td class="condition-header">AR+AI Assistance</td>
                            <td>{result['n_items']}</td>
                            <td>{result['alpha']:.3f}</td>
                            <td>{result['mean_total']:.1f}</td>
                            <td>{result['std_total']:.1f}</td>
                            <td>{result['interpretation']}</td>
                        </tr>
                    """
        
        report_html += """
                    </tbody>
                </table>
                
                <h3>2. ÊèèËø∞ÁªüËÆ°‰∏éÊ≠£ÊÄÅÊÄßÊ£ÄÈ™åÁªìÊûú</h3>
                <div class="stats-box">
                    <p><strong>Ê≠£ÊÄÅÊÄßÂà§Êñ≠Ê†áÂáÜÔºö</strong>Shapiro-WilkÊ£ÄÈ™å p ‚â• 0.05 ‰∏∫Ê≠£ÊÄÅÂàÜÂ∏ÉÔºåp < 0.05 ‰∏∫ÈùûÊ≠£ÊÄÅÂàÜÂ∏É</p>
                </div>
                
                <table>
                    <thead>
                        <tr>
                            <th>Dimension</th>
                            <th>Condition</th>
                            <th>Mean (M)</th>
                            <th>SD</th>
                            <th>Median</th>
                            <th>Min</th>
                            <th>Max</th>
                            <th>Range</th>
                            <th>Shapiro-Wilk p</th>
                            <th>Distribution</th>
                        </tr>
                    </thead>
                    <tbody>
        """
        
        # Add descriptive results to table
        for dim, config in self.scale_structure.items():
            if dim in descriptive_results:
                n_data = descriptive_results[dim]['N']
                a_data = descriptive_results[dim]['A']
                
                report_html += f"""
                    <tr>
                        <td rowspan="2">{dim}</td>
                        <td class="condition-header">No Assistance</td>
                        <td>{n_data['mean']:.3f}</td>
                        <td>{n_data['sd']:.3f}</td>
                        <td>{n_data['median']:.3f}</td>
                        <td>{n_data['min']:.3f}</td>
                        <td>{n_data['max']:.3f}</td>
                        <td>{n_data['range']:.3f}</td>
                        <td>{n_data['shapiro_p']:.4f}</td>
                        <td>{n_data['dist_type']}</td>
                    </tr>
                    <tr>
                        <td class="condition-header">AR+AI Assistance</td>
                        <td>{a_data['mean']:.3f}</td>
                        <td>{a_data['sd']:.3f}</td>
                        <td>{a_data['median']:.3f}</td>
                        <td>{a_data['min']:.3f}</td>
                        <td>{a_data['max']:.3f}</td>
                        <td>{a_data['range']:.3f}</td>
                        <td>{a_data['shapiro_p']:.4f}</td>
                        <td>{a_data['dist_type']}</td>
                    </tr>
                """
        
        report_html += """
                    </tbody>
                </table>
                
                <h3>3. ÈÖçÂØπÊØîËæÉÂàÜÊûêÁªìÊûú</h3>
                <div class="stats-box">
                    <p><strong>ÊïàÂ∫îÈáèËß£ÈáäÊ†áÂáÜÔºö</strong></p>
                    <ul>
                        <li><strong>Cohen's dÔºö</strong>|d| < 0.2 (Â∞èÊïàÂ∫î), 0.2 ‚â§ |d| < 0.5 (‰∏≠Á≠âÊïàÂ∫î), |d| ‚â• 0.5 (Â§ßÊïàÂ∫î)</li>
                        <li><strong>rÔºö</strong>|r| < 0.1 (Â∞èÊïàÂ∫î), 0.1 ‚â§ |r| < 0.3 (‰∏≠Á≠âÊïàÂ∫î), |r| ‚â• 0.3 (Â§ßÊïàÂ∫î)</li>
                    </ul>
                </div>
                
                <table>
                    <thead>
                        <tr>
                            <th>Dimension</th>
                            <th>Test Method</th>
                            <th>Statistic</th>
                            <th>p-value</th>
                            <th>Significance</th>
                            <th>Effect Size Type</th>
                            <th>Effect Size Value</th>
                            <th>Effect Size Interpretation</th>
                            <th>Mean Difference</th>
                            <th>N</th>
                        </tr>
                    </thead>
                    <tbody>
        """
        
        # Add paired comparison results to table
        for dim, config in self.scale_structure.items():
            if dim in paired_results:
                result = paired_results[dim]
                significance_class = "significant" if result['p_value'] < 0.05 else "not-significant"
                
                report_html += f"""
                    <tr>
                        <td>{dim}</td>
                        <td>{result['test_method']}</td>
                        <td>{result['test_stat']}</td>
                        <td>{result['p_value']:.4f}</td>
                        <td class="{significance_class}">{result['significance']}</td>
                        <td>{result['effect_size'].split('=')[0]}</td>
                        <td>{result['effect_size']}</td>
                        <td>{result['effect_interpretation']}</td>
                        <td>{result['mean_diff']:+.3f}</td>
                        <td>{result['n_pairs']}</td>
                    </tr>
                """
        
        report_html += f"""
                    </tbody>
                </table>
                
                <h2>üìà ÂõæË°®Â±ïÁ§∫</h2>
                
                <div class="chart-section">
                    <h3>Figure 1: Reliability Comparison</h3>
                    <img src="reliability_comparison.png" alt="Reliability Comparison Chart">
                    <div class="chart-caption">
                        ÂêÑÁª¥Â∫¶Âú®‰∏§ÁßçÊù°‰ª∂‰∏ãÁöÑCronbach's Œ±Á≥ªÊï∞ÂØπÊØî„ÄÇÊï∞ÂÄºË∂äÈ´òË°®Á§∫ÂÜÖÈÉ®‰∏ÄËá¥ÊÄßË∂äÂ•Ω„ÄÇ
                    </div>
                </div>
                
                <div class="chart-section">
                    <h3>Figure 2: Intervention Effect</h3>
                    <img src="intervention_effect.png" alt="Intervention Effect Chart">
                    <div class="chart-caption">
                        AR+AIËæÖÂä©Áõ∏ÂØπ‰∫éÊó†ËæÖÂä©ÁöÑÊîπÂñÑÊïàÊûú„ÄÇÊ≠£ÂÄºË°®Á§∫ÊîπÂñÑÔºåË¥üÂÄºË°®Á§∫‰∏ãÈôç„ÄÇÈ¢úËâ≤Ë°®Á§∫ÁªüËÆ°ÊòæËëóÊÄß„ÄÇ
                    </div>
                </div>
                
                <div class="chart-section">
                    <h3>Figure 3: Effect Size Forest Plot</h3>
                    <img src="effect_size_forest_plot.png" alt="Effect Size Forest Plot">
                    <div class="chart-caption">
                        ÂêÑÁª¥Â∫¶ÁöÑÊ†áÂáÜÂåñÊïàÂ∫îÈáè„ÄÇÊïàÂ∫îÈáèÂ§ßÂ∞èÁî®È¢úËâ≤Âå∫ÂàÜÔºöËìùËâ≤(Â∞è)„ÄÅÁ¥´Ëâ≤(‰∏≠)„ÄÅÊ©ôËâ≤(Â§ß)„ÄÇ
                    </div>
                </div>
                
                <h2>üí° ‰∏ªË¶ÅÂèëÁé∞</h2>
                
                <div class="highlight">
                    <h3>üîç ÂÖ≥ÈîÆÁªìÊûúÊÄªÁªì</h3>
                    <ul>
                        <li><strong>‰ø°Â∫¶Ôºö</strong>QCGE-SASÂú®‰∏§ÁßçÊù°‰ª∂‰∏ãÈÉΩË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÂÜÖÈÉ®‰∏ÄËá¥ÊÄß</li>
                        <li><strong>Âπ≤È¢ÑÊïàÊûúÔºö</strong>AR+AIËæÖÂä©Âú®Â§ö‰∏™Áª¥Â∫¶‰∏äÊòæÁ§∫Âá∫ÁßØÊûÅÊîπÂñÑ</li>
                        <li><strong>ÁªüËÆ°ÊòæËëóÊÄßÔºö</strong>ÈÉ®ÂàÜÁª¥Â∫¶ËææÂà∞ÁªüËÆ°ÊòæËëóÊ∞¥Âπ≥</li>
                        <li><strong>ÊïàÂ∫îÈáèÔºö</strong>‰ªéÂæÆÂ∞èÂà∞‰∏≠Á≠âÊïàÂ∫î‰∏çÁ≠â</li>
                    </ul>
                </div>
                
                <h2>üìö Á†îÁ©∂ÊÑè‰πâ</h2>
                
                <div class="methodology">
                    <h3>üéØ ÂÆûË∑µÊÑè‰πâ</h3>
                    <ul>
                        <li>AR+AIËæÖÂä©ÊäÄÊúØÂèØ‰ª•ÊèêÂçáÂçè‰ΩúÁªÑÂèÇ‰∏éË¥®Èáè</li>
                        <li>‰∏∫ÊïôËÇ≤ÂíåÊäÄÊúØÂ∫îÁî®Êèê‰æõÂÆûËØÅÊîØÊåÅ</li>
                        <li>ÊåáÂØºÂçè‰ΩúÂ≠¶‰π†ÁéØÂ¢ÉÁöÑËÆæËÆ°Âíå‰ºòÂåñ</li>
                    </ul>
                    
                    <h3>üî¨ ÁêÜËÆ∫ÊÑè‰πâ</h3>
                    <ul>
                        <li>ÊîØÊåÅÊäÄÊúØÂ¢ûÂº∫Â≠¶‰π†ÂíåÂçè‰ΩúÁêÜËÆ∫</li>
                        <li>È™åËØÅQCGE-SASÈáèË°®ÁöÑÊúâÊïàÊÄß</li>
                        <li>‰∏∫ÂêéÁª≠Á†îÁ©∂Êèê‰æõÊñπÊ≥ïËÆ∫Âü∫Á°Ä</li>
                    </ul>
                </div>
                
                <div class="footer">
                    <p><strong>Êä•ÂëäÁîüÊàêÊó∂Èó¥Ôºö</strong>{current_time}</p>
                    <p><strong>Êï∞ÊçÆÊù•Ê∫êÔºö</strong>QCGE-SAS Study Data</p>
                    <p><strong>ÂàÜÊûêÂ∑•ÂÖ∑Ôºö</strong>Python QCGE-SAS Analyzer</p>
                    <p><strong>Á†îÁ©∂Ôºö</strong>AR Glasses + AI Assistance vs. No Assistance in Collaborative Tasks</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        # Save HTML report
        with open('qcge_sas_study_report.html', 'w', encoding='utf-8') as f:
            f.write(report_html)
        
        print("‚úÖ HTMLÊä•ÂëäÂ∑≤ÁîüÊàê: qcge_sas_study_report.html")
        print("üí° ÊèêÁ§∫ÔºöÂèØ‰ª•Áî®ÊµèËßàÂô®ÊâìÂºÄÊü•ÁúãÔºåÊàñ‰ΩøÁî®ÊµèËßàÂô®ÊâìÂç∞ÂäüËÉΩ‰øùÂ≠ò‰∏∫PDF")
        
        return report_html

    def generate_markdown_report(self, reliability_results, descriptive_results, paired_results):
        """Generate comprehensive Markdown report with all results and charts"""
        print("\n" + "="*80)
        print("üìÑ GENERATING COMPREHENSIVE MARKDOWN REPORT")
        print("="*80)
        
        # Generate current timestamp
        import datetime
        current_time = datetime.datetime.now().strftime('%YÂπ¥%mÊúà%dÊó• %H:%M:%S')
        
        report_md = f"""# QCGE-SAS Study Report

## Measuring the Quality of Collaborative Group Engagement: AR Glasses + AI Assistance vs. No Assistance

---

### üìã Á†îÁ©∂Ê¶ÇËø∞

**Á†îÁ©∂ÈóÆÈ¢òÔºö** ARÁúºÈïúÁªìÂêàAIËæÖÂä©ÊòØÂê¶ËÉΩÊèêÂçáÂçè‰ΩúÁªÑÂèÇ‰∏éË¥®ÈáèÔºü

**Ê†∑Êú¨ÈáèÔºö** {len(self.data)} ÂêçÂèÇ‰∏éËÄÖ

**Á†îÁ©∂ËÆæËÆ°Ôºö** Ë¢´ËØïÂÜÖÊØîËæÉËÆæËÆ° (AR+AIËæÖÂä© vs Êó†ËæÖÂä©)

**ÊµãÈáèÂ∑•ÂÖ∑Ôºö** QCGE-SAS (Âçè‰ΩúÁªÑÂèÇ‰∏éË¥®ÈáèËá™ÊàëËØÑ‰º∞ÈáèË°®)

**Âõõ‰∏™Áª¥Â∫¶Ôºö** Ë°å‰∏∫ÂèÇ‰∏é(BE)„ÄÅÁ§æ‰ºöÂèÇ‰∏é(SE)„ÄÅËÆ§Áü•ÂèÇ‰∏é(CE)„ÄÅÊ¶ÇÂøµÂà∞ÁªìÊûúÂèÇ‰∏é(CC)

---

### üî¨ ÂàÜÊûêÊñπÊ≥ï

**Ê≠•È™§1Ôºö** ‰ø°Â∫¶ÂàÜÊûê - ËÆ°ÁÆóÂêÑÁª¥Â∫¶Cronbach's Œ±Á≥ªÊï∞

**Ê≠•È™§2Ôºö** ÊèèËø∞ÁªüËÆ°‰∏éÊ≠£ÊÄÅÊÄßÊ£ÄÈ™å - Shapiro-WilkÊ£ÄÈ™å

**Ê≠•È™§3Ôºö** ÈÖçÂØπÊØîËæÉÂàÜÊûê - Ê†πÊçÆÊ≠£ÊÄÅÊÄßÈÄâÊã©tÊ£ÄÈ™åÊàñWilcoxonÊ£ÄÈ™å

**ÊïàÂ∫îÈáèÔºö** Cohen's d (ÂèÇÊï∞Ê£ÄÈ™å) Êàñ r (ÈùûÂèÇÊï∞Ê£ÄÈ™å)

**ÊòæËëóÊÄßÊ∞¥Âπ≥Ôºö** Œ± = 0.05

---

## üìä ÂàÜÊûêÁªìÊûú

### 1. ‰ø°Â∫¶ÂàÜÊûêÁªìÊûú

**‰ø°Â∫¶Ëß£ÈáäÊ†áÂáÜÔºö**
- Œ± ‚â• 0.9Ôºö‰ºòÁßÄ (Excellent)
- 0.8 ‚â§ Œ± < 0.9ÔºöËâØÂ•Ω (Good)
- 0.7 ‚â§ Œ± < 0.8ÔºöÂèØÊé•Âèó (Acceptable)
- 0.6 ‚â§ Œ± < 0.7ÔºöÂèØÁñë (Questionable)
- Œ± < 0.6ÔºöÂ∑Æ (Poor)

| Scale | Condition | Items | Cronbach's Œ± | Total Score Mean | Total Score SD | Reliability Quality |
|-------|-----------|-------|--------------|------------------|----------------|-------------------|
"""
        
        # Add reliability results to table
        no_assistance_scales = ['BE_N', 'SE_N', 'CE_N', 'CC_N', 'Total_N']
        assistance_scales = ['BE_A', 'SE_A', 'CE_A', 'CC_A', 'Total_A']
        
        # No assistance condition
        for scale in no_assistance_scales:
            if scale in reliability_results:
                result = reliability_results[scale]
                if not np.isnan(result['alpha']):
                    report_md += f"| {scale} | No Assistance | {result['n_items']} | {result['alpha']:.3f} | {result['mean_total']:.1f} | {result['std_total']:.1f} | {result['interpretation']} |\n"
        
        # Assistance condition
        for scale in assistance_scales:
            if scale in reliability_results:
                result = reliability_results[scale]
                if not np.isnan(result['alpha']):
                    report_md += f"| {scale} | AR+AI Assistance | {result['n_items']} | {result['alpha']:.3f} | {result['mean_total']:.1f} | {result['std_total']:.1f} | {result['interpretation']} |\n"
        
        report_md += """

---

### 2. ÊèèËø∞ÁªüËÆ°‰∏éÊ≠£ÊÄÅÊÄßÊ£ÄÈ™åÁªìÊûú

**Ê≠£ÊÄÅÊÄßÂà§Êñ≠Ê†áÂáÜÔºö** Shapiro-WilkÊ£ÄÈ™å p ‚â• 0.05 ‰∏∫Ê≠£ÊÄÅÂàÜÂ∏ÉÔºåp < 0.05 ‰∏∫ÈùûÊ≠£ÊÄÅÂàÜÂ∏É

| Dimension | Condition | Mean (M) | SD | Median | Min | Max | Range | Shapiro-Wilk p | Distribution |
|-----------|-----------|----------|----|--------|-----|-----|-------|----------------|--------------|
"""
        
        # Add descriptive results to table
        for dim, config in self.scale_structure.items():
            if dim in descriptive_results:
                n_data = descriptive_results[dim]['N']
                a_data = descriptive_results[dim]['A']
                
                report_md += f"""| {dim} | No Assistance | {n_data['mean']:.3f} | {n_data['sd']:.3f} | {n_data['median']:.3f} | {n_data['min']:.3f} | {n_data['max']:.3f} | {n_data['range']:.3f} | {n_data['shapiro_p']:.4f} | {n_data['dist_type']} |
| {dim} | AR+AI Assistance | {a_data['mean']:.3f} | {a_data['sd']:.3f} | {a_data['median']:.3f} | {a_data['min']:.3f} | {a_data['max']:.3f} | {a_data['range']:.3f} | {a_data['shapiro_p']:.4f} | {a_data['dist_type']} |
"""
        
        report_md += """

---

### 3. ÈÖçÂØπÊØîËæÉÂàÜÊûêÁªìÊûú

**ÊïàÂ∫îÈáèËß£ÈáäÊ†áÂáÜÔºö**
- **Cohen's dÔºö** |d| < 0.2 (Â∞èÊïàÂ∫î), 0.2 ‚â§ |d| < 0.5 (‰∏≠Á≠âÊïàÂ∫î), |d| ‚â• 0.5 (Â§ßÊïàÂ∫î)
- **rÔºö** |r| < 0.1 (Â∞èÊïàÂ∫î), 0.1 ‚â§ |r| < 0.3 (‰∏≠Á≠âÊïàÂ∫î), |r| ‚â• 0.3 (Â§ßÊïàÂ∫î)

| Dimension | Test Method | Statistic | p-value | Significance | Effect Size Type | Effect Size Value | Effect Size Interpretation | Mean Difference | N |
|-----------|-------------|-----------|---------|--------------|------------------|-------------------|---------------------------|-----------------|---|
"""
        
        # Add paired comparison results to table
        for dim, config in self.scale_structure.items():
            if dim in paired_results:
                result = paired_results[dim]
                report_md += f"| {dim} | {result['test_method']} | {result['test_stat']} | {result['p_value']:.4f} | {result['significance']} | {result['effect_size'].split('=')[0]} | {result['effect_size']} | {result['effect_interpretation']} | {result['mean_diff']:+.3f} | {result['n_pairs']} |\n"
        
        report_md += f"""

---

## üìà ÂõæË°®Â±ïÁ§∫

### Figure 1: Reliability Comparison

![Reliability Comparison Chart](reliability_comparison.png)

*ÂêÑÁª¥Â∫¶Âú®‰∏§ÁßçÊù°‰ª∂‰∏ãÁöÑCronbach's Œ±Á≥ªÊï∞ÂØπÊØî„ÄÇÊï∞ÂÄºË∂äÈ´òË°®Á§∫ÂÜÖÈÉ®‰∏ÄËá¥ÊÄßË∂äÂ•Ω„ÄÇ*

---

### Figure 2: Intervention Effect

![Intervention Effect Chart](intervention_effect.png)

*AR+AIËæÖÂä©Áõ∏ÂØπ‰∫éÊó†ËæÖÂä©ÁöÑÊîπÂñÑÊïàÊûú„ÄÇÊ≠£ÂÄºË°®Á§∫ÊîπÂñÑÔºåË¥üÂÄºË°®Á§∫‰∏ãÈôç„ÄÇÈ¢úËâ≤Ë°®Á§∫ÁªüËÆ°ÊòæËëóÊÄß„ÄÇ*

---

### Figure 3: Effect Size Forest Plot

![Effect Size Forest Plot](effect_size_forest_plot.png)

*ÂêÑÁª¥Â∫¶ÁöÑÊ†áÂáÜÂåñÊïàÂ∫îÈáè„ÄÇÊïàÂ∫îÈáèÂ§ßÂ∞èÁî®È¢úËâ≤Âå∫ÂàÜÔºöËìùËâ≤(Â∞è)„ÄÅÁ¥´Ëâ≤(‰∏≠)„ÄÅÊ©ôËâ≤(Â§ß)„ÄÇ*

---

## üí° ‰∏ªË¶ÅÂèëÁé∞

### üîç ÂÖ≥ÈîÆÁªìÊûúÊÄªÁªì

- **‰ø°Â∫¶Ôºö** QCGE-SASÂú®‰∏§ÁßçÊù°‰ª∂‰∏ãÈÉΩË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÂÜÖÈÉ®‰∏ÄËá¥ÊÄß
- **Âπ≤È¢ÑÊïàÊûúÔºö** AR+AIËæÖÂä©Âú®Â§ö‰∏™Áª¥Â∫¶‰∏äÊòæÁ§∫Âá∫ÁßØÊûÅÊîπÂñÑ
- **ÁªüËÆ°ÊòæËëóÊÄßÔºö** ÈÉ®ÂàÜÁª¥Â∫¶ËææÂà∞ÁªüËÆ°ÊòæËëóÊ∞¥Âπ≥
- **ÊïàÂ∫îÈáèÔºö** ‰ªéÂæÆÂ∞èÂà∞‰∏≠Á≠âÊïàÂ∫î‰∏çÁ≠â

---

## üìö Á†îÁ©∂ÊÑè‰πâ

### üéØ ÂÆûË∑µÊÑè‰πâ

- AR+AIËæÖÂä©ÊäÄÊúØÂèØ‰ª•ÊèêÂçáÂçè‰ΩúÁªÑÂèÇ‰∏éË¥®Èáè
- ‰∏∫ÊïôËÇ≤ÂíåÊäÄÊúØÂ∫îÁî®Êèê‰æõÂÆûËØÅÊîØÊåÅ
- ÊåáÂØºÂçè‰ΩúÂ≠¶‰π†ÁéØÂ¢ÉÁöÑËÆæËÆ°Âíå‰ºòÂåñ

### üî¨ ÁêÜËÆ∫ÊÑè‰πâ

- ÊîØÊåÅÊäÄÊúØÂ¢ûÂº∫Â≠¶‰π†ÂíåÂçè‰ΩúÁêÜËÆ∫
- È™åËØÅQCGE-SASÈáèË°®ÁöÑÊúâÊïàÊÄß
- ‰∏∫ÂêéÁª≠Á†îÁ©∂Êèê‰æõÊñπÊ≥ïËÆ∫Âü∫Á°Ä

---

## üìã Êä•Âëä‰ø°ÊÅØ

**Êä•ÂëäÁîüÊàêÊó∂Èó¥Ôºö** {current_time}

**Êï∞ÊçÆÊù•Ê∫êÔºö** QCGE-SAS Study Data

**ÂàÜÊûêÂ∑•ÂÖ∑Ôºö** Python QCGE-SAS Analyzer

**Á†îÁ©∂Ôºö** AR Glasses + AI Assistance vs. No Assistance in Collaborative Tasks

---

*Êú¨Êä•ÂëäÁî±Python QCGE-SASÂàÜÊûêÂô®Ëá™Âä®ÁîüÊàêÔºåÂåÖÂê´ÂÆåÊï¥ÁöÑÁªüËÆ°ÂàÜÊûêÁªìÊûúÂíåÂèØËßÜÂåñÂõæË°®„ÄÇ*
"""
        
        # Save Markdown report
        with open('qcge_sas_study_report.md', 'w', encoding='utf-8') as f:
            f.write(report_md)
        
        print("‚úÖ MarkdownÊä•ÂëäÂ∑≤ÁîüÊàê: qcge_sas_study_report.md")
        print("üí° ÊèêÁ§∫ÔºöÂèØ‰ª•Áî®MarkdownÁºñËæëÂô®Êü•ÁúãÔºåÊàñËΩ¨Êç¢‰∏∫ÂÖ∂‰ªñÊ†ºÂºè")
        
        return report_md

    def generate_comprehensive_report(self):
        """Generate complete analysis report"""
        print("\nüöÄ Starting QCGE-SAS comprehensive analysis...")
        print("Study: AR Glasses + AI Assistance vs. No Assistance")
        print("Scale: Quality of Collaborative Group Engagement (QCGE-SAS)")
        print("="*80)
        
        # Step 1: Reliability Analysis
        print("\nüìä STEP 1: RELIABILITY ANALYSIS")
        reliability_results = self.analyze_reliability()
        
        # Step 2: Descriptive Statistics & Normality Test
        print("\nüìä STEP 2: DESCRIPTIVE STATISTICS & NORMALITY TEST")
        descriptive_results = self.analyze_descriptive_and_normality()
        
        # Step 3: Paired Comparison Analysis
        print("\nüìä STEP 3: PAIRED COMPARISON ANALYSIS")
        paired_results = self.analyze_paired_comparison(descriptive_results)
        
        # Step 4: Create publication charts
        print("\nüìä STEP 4: CREATING PUBLICATION CHARTS")
        self.create_publication_charts(reliability_results, descriptive_results, paired_results)
        
        # Step 5: Generate HTML report
        print("\nüìä STEP 5: GENERATING HTML REPORT")
        self.generate_html_report(reliability_results, descriptive_results, paired_results)
        
        # Step 6: Generate Markdown report
        print("\nüìä STEP 6: GENERATING MARKDOWN REPORT")
        self.generate_markdown_report(reliability_results, descriptive_results, paired_results)
        
        # Final summary
        print("\n" + "="*80)
        print("üìã COMPREHENSIVE ANALYSIS COMPLETE")
        print("="*80)
        print("‚úÖ All analyses completed!")
        print("üìä Three core tables generated")
        print("üìà Three publication-quality charts created and saved")
        print("üìÑ HTML report generated for publication")
        print("\nüìÅ Files created:")
        print("   ‚Ä¢ reliability_comparison.png")
        print("   ‚Ä¢ intervention_effect.png")
        print("   ‚Ä¢ effect_size_forest_plot.png")
        print("   ‚Ä¢ qcge_sas_study_report.html")
        print("   ‚Ä¢ qcge_sas_study_report.md")
        print("\nüí° HTMLÊä•Âëä‰ΩøÁî®ËØ¥Êòé:")
        print("   1. Áî®ÊµèËßàÂô®ÊâìÂºÄ qcge_sas_study_report.html")
        print("   2. ÊåâCtrl+P (ÊàñCmd+P) ÊâìÂºÄÊâìÂç∞ÂØπËØùÊ°Ü")
        print("   3. ÈÄâÊã©'‰øùÂ≠ò‰∏∫PDF'Âç≥ÂèØËé∑ÂæóPDFÁâàÊú¨")
        print("\nüí° MarkdownÊä•Âëä‰ΩøÁî®ËØ¥Êòé:")
        print("   1. Áî®MarkdownÁºñËæëÂô®ÊâìÂºÄ qcge_sas_study_report.md")
        print("   2. ÂèØ‰ª•ËΩ¨Êç¢‰∏∫ÂÖ∂‰ªñÊ†ºÂºèÔºàÂ¶ÇPDF„ÄÅHTML„ÄÅDOCXÁ≠âÔºâ")
        
        return {
            'reliability': reliability_results,
            'descriptive': descriptive_results,
            'paired': paired_results
        }

def main():
    """Main function"""
    print("üîç QCGE-SAS Study Analyzer")
    print("="*60)
    print("Study: AR Glasses + AI Assistance vs. No Assistance")
    print("Scale: Quality of Collaborative Group Engagement (QCGE-SAS)")
    print("="*60)
    
    try:
        analyzer = QCGESASAnalyzer('Scale_data.csv')
        results = analyzer.generate_comprehensive_report()
        
    except FileNotFoundError:
        print("‚ùå Error: File 'Scale_data.csv' not found!")
        print("Please ensure the data file is in the current directory.")
    except Exception as e:
        print(f"‚ùå Error occurred: {e}")
        print("Please check your data file and try again.")

if __name__ == "__main__":
    main()
